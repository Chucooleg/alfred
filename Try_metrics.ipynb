{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['ALFRED_ROOT'] = '/root/data/home/hoyeung/alfred/'\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.environ['ALFRED_ROOT']))\n",
    "sys.path.append(os.path.join(os.environ['ALFRED_ROOT'], 'models'))\n",
    "\n",
    "import torch\n",
    "import pprint\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading https://files.pythonhosted.org/packages/43/cc/e18e33be20971ff73a056ebdb023476b5a545e744e3fc22acd8c758f1e0d/rouge-1.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: six in /opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages (from rouge) (1.12.0)\n",
      "Installing collected packages: rouge\n",
      "\u001b[33m  WARNING: The script rouge is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed rouge-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    pass\n",
    "\n",
    "# settings\n",
    "args.seed = 123\n",
    "args.data = '/root/data_alfred/json_feat_2.1.0'\n",
    "args.splits = '/root/data_alfred/splits/oct21.json'\n",
    "args.preprocess = False #!\n",
    "args.pp_folder = 'pp'\n",
    "args.save_every_epoch = False #!\n",
    "args.model = 'seq2seq_im'\n",
    "args.gpu = True\n",
    "args.dout = 'exp/model:seq2seq_im'\n",
    "args.resume = False #!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vocab objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = torch.load(os.path.join(args.data, \"%s.vocab\" % args.pp_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# splits\n",
    "\n",
    "\n",
    "- Load here\n",
    "https://github.com/Chucooleg/alfred/blob/6d2a6d9b210ea2ab57a3d6c6b2810f796e9ad2d1/models/train/train_seq2seq.py#L80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tests_seen': 1533,\n",
      " 'tests_unseen': 1529,\n",
      " 'train': 21023,\n",
      " 'valid_seen': 820,\n",
      " 'valid_unseen': 821}\n"
     ]
    }
   ],
   "source": [
    "# load train/valid/tests splits\n",
    "with open(args.splits) as f:\n",
    "    splits = json.load(f)\n",
    "    pprint.pprint({k: len(v) for k, v in splits.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'repeat_idx': 0,\n",
       " 'task': 'pick_cool_then_place_in_recep-LettuceSliced-None-DiningTable-17/trial_T20190909_070538_437648'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_task_set = [t for t in splits['train'] if t['repeat_idx'] == 0]\n",
    "valid_seen_task_set = [t for t in splits['valid_seen'] if t['repeat_idx'] == 0]\n",
    "valid_unseen_task_set = [t for t in splits['valid_unseen'] if t['repeat_idx'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6574\n",
      "251\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "print(len(train_task_set))\n",
    "print(len(valid_seen_task_set))\n",
    "print(len(valid_unseen_task_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch\n",
    "\n",
    "- Loaded here https://github.com/Chucooleg/alfred/blob/6d2a6d9b210ea2ab57a3d6c6b2810f796e9ad2d1/models/model/seq2seq.py#L277"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_task_jsons(task):\n",
    "    '''\n",
    "    load all preprocessed jsons with matching task index from disk. \n",
    "    do this to gather all 3 versions of language annotations.\n",
    "    '''\n",
    "    dataset = []\n",
    "    for i in range(3):\n",
    "        json_path = os.path.join(args.data, task['task'], '%s' % args.pp_folder, 'ann_%d.json' % i)\n",
    "        if os.path.exists(json_path):\n",
    "            retry = 0\n",
    "            while True:\n",
    "                try:\n",
    "                    if retry > 0:\n",
    "                        print ('retrying {}'.format(retry))\n",
    "                    with open(json_path) as f:\n",
    "                        dataset.append(json.load(f))\n",
    "                    break\n",
    "                except:\n",
    "                    retry += 1\n",
    "                    time.sleep(5)\n",
    "                    pass\n",
    "    return dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exs = load_task_jsons(train_task_set[0])\n",
    "len(exs[0]['ann']['instr']) == len(exs[1]['ann']['instr']) == len(exs[2]['ann']['instr'])\n",
    "num_subgoals = len(exs[0]['ann']['instr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "exs_pos_to_tokens = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "exs_tag_to_tokens = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "\n",
    "for ex in exs:\n",
    "    \n",
    "    pos_to_tokens = defaultdict(lambda: defaultdict(list))\n",
    "    tag_to_tokens = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    for subgoal_i, subgoal in enumerate(ex['ann']['instr']):\n",
    "        sent = nlp(' '.join(subgoal))\n",
    "        for i, token in enumerate(sent):\n",
    "            exs_pos_to_tokens[token.pos_][subgoal_i][ex['repeat_idx']].append(str(token))\n",
    "            exs_tag_to_tokens[token.tag_][subgoal_i][ex['repeat_idx']].append(str(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>.<locals>.<lambda>()>,\n",
       "            {0: defaultdict(list,\n",
       "                         {0: ['turn', 'counter'],\n",
       "                          1: ['knife', 'table'],\n",
       "                          2: ['slice', 'vegetable', 'table'],\n",
       "                          3: ['turn', 'right', 'fridge'],\n",
       "                          4: ['fridge', 'knife', 'fridge', 'fridge'],\n",
       "                          5: ['turn', 'turn', 'counter'],\n",
       "                          6: ['slice', 'vegetable'],\n",
       "                          7: ['turn', 'turn', 'right', 'fridge'],\n",
       "                          8: ['fridge',\n",
       "                           'slice',\n",
       "                           'knife',\n",
       "                           'fridge',\n",
       "                           'fridge',\n",
       "                           'slice',\n",
       "                           'fridge'],\n",
       "                          9: ['turn',\n",
       "                           'turn',\n",
       "                           'turn',\n",
       "                           'turn',\n",
       "                           'right',\n",
       "                           'counter'],\n",
       "                          10: ['put', 'slice', 'counter']}),\n",
       "             1: defaultdict(list,\n",
       "                         {0: ['turn', 'stool', 'walk', 'table'],\n",
       "                          1: ['knife', 'yellow', 'handle', 'middle', 'table'],\n",
       "                          2: ['slice', 'head', 'lettuce', 'table'],\n",
       "                          3: ['turn', 'walk', 'fridge', 'right'],\n",
       "                          4: ['put',\n",
       "                           'knife',\n",
       "                           'fridge',\n",
       "                           'top',\n",
       "                           'shelf',\n",
       "                           'left',\n",
       "                           'loaf',\n",
       "                           'bread',\n",
       "                           'door'],\n",
       "                          5: ['turn', 'walk', 'table'],\n",
       "                          6: ['slice', 'lettuce', 'table'],\n",
       "                          7: ['turn', 'walk', 'fridge', 'right'],\n",
       "                          8: ['put',\n",
       "                           'slice',\n",
       "                           'lettuce',\n",
       "                           'fridge',\n",
       "                           'top',\n",
       "                           'shelf',\n",
       "                           'knife',\n",
       "                           'chill',\n",
       "                           'door'],\n",
       "                          9: ['turn',\n",
       "                           'head',\n",
       "                           'stool',\n",
       "                           'right',\n",
       "                           'turn',\n",
       "                           'face',\n",
       "                           'table'],\n",
       "                          10: ['put',\n",
       "                           'slice',\n",
       "                           'lettuce',\n",
       "                           'table',\n",
       "                           'front',\n",
       "                           'head',\n",
       "                           'lettuce']}),\n",
       "             2: defaultdict(list,\n",
       "                         {0: ['turn', 'move', 'table'],\n",
       "                          1: ['knife', 'table'],\n",
       "                          2: ['use', 'knife', 'slice', 'head', 'lettuce'],\n",
       "                          3: ['knife', 'fridge'],\n",
       "                          4: ['place', 'knife', 'top', 'shelf', 'fridge'],\n",
       "                          5: ['turn', 'move', 'front', 'lettuce', 'table'],\n",
       "                          6: ['piece', 'lettuce', 'table'],\n",
       "                          7: ['turn', 'slice', 'lettuce', 'fridge'],\n",
       "                          8: ['place',\n",
       "                           'lettuce',\n",
       "                           'top',\n",
       "                           'shelf',\n",
       "                           'fridge',\n",
       "                           'door',\n",
       "                           'lettuce',\n",
       "                           'couple',\n",
       "                           'seconds'],\n",
       "                          9: ['turn', 'lettuce', 'front', 'table'],\n",
       "                          10: ['place',\n",
       "                           'lettuce',\n",
       "                           'slice',\n",
       "                           'table',\n",
       "                           'front',\n",
       "                           'rest',\n",
       "                           'head',\n",
       "                           'lettuce']})})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for subgoal_i in num_subgoals:\n",
    "    exs_pos_to_tokens['NOUN'][subgoal_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0: ['turn', 'counter'],\n",
       "             1: ['turn', 'stool', 'walk', 'table'],\n",
       "             2: ['turn', 'move', 'table']})"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exs_pos_to_tokens['NOUN'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "sentence_bleu([['turn', 'counter'], ['turn', 'stool', 'walk', 'table']], ['turn', 'move', 'table'], weights=(1,0,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-c11453874ec4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrouge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRouge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrouge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRouge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrouge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'turn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'move'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'table'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'turn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stool'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'walk'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'table'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/rouge/rouge.py\u001b[0m in \u001b[0;36mget_scores\u001b[0;34m(self, hyps, refs, avg, ignore_empty)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_avg_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/rouge/rouge.py\u001b[0m in \u001b[0;36m_get_scores\u001b[0;34m(self, hyps, refs)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0msen_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mhyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0mref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge \n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores([['turn', 'move', 'table']], [['turn', 'stool', 'walk', 'table']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-fa8cef49474b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'scores' is not defined"
     ]
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'_SP': [' ', '  ', ' ', '  ', '  ', '  ', '  ', '  ', ' '],\n",
       "             'VB': ['walk'],\n",
       "             'JJ': ['straight'],\n",
       "             ',': [','],\n",
       "             'NN': ['turn', 'counter'],\n",
       "             'VBN': ['left'],\n",
       "             'TO': ['to'],\n",
       "             'DT': ['the'],\n",
       "             '.': ['.']})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'SPACE': [' ', '  ', ' ', '  ', '  ', '  ', '  ', '  ', ' '],\n",
       "             'VERB': ['walk', 'left'],\n",
       "             'ADJ': ['straight'],\n",
       "             'PUNCT': [',', '.'],\n",
       "             'NOUN': ['turn', 'counter'],\n",
       "             'PART': ['to'],\n",
       "             'DET': ['the']})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_to_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SPACE',\n",
       " 'VERB',\n",
       " 'SPACE',\n",
       " 'ADJ',\n",
       " 'SPACE',\n",
       " 'PUNCT',\n",
       " 'SPACE',\n",
       " 'NOUN',\n",
       " 'SPACE',\n",
       " 'VERB',\n",
       " 'SPACE',\n",
       " 'PART',\n",
       " 'SPACE',\n",
       " 'DET',\n",
       " 'SPACE',\n",
       " 'NOUN',\n",
       " 'SPACE',\n",
       " 'PUNCT']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_cat = 'NOUN'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

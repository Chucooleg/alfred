{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['ALFRED_ROOT'] = '/root/data/home/hoyeung/alfred/'\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.environ['ALFRED_ROOT']))\n",
    "sys.path.append(os.path.join(os.environ['ALFRED_ROOT'], 'gen'))\n",
    "sys.path.append(os.path.join(os.environ['ALFRED_ROOT'], 'models'))\n",
    "\n",
    "import torch\n",
    "import pprint\n",
    "import json\n",
    "from data.preprocess import Dataset\n",
    "from importlib import import_module, reload\n",
    "from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser\n",
    "from models.utils.helper_utils import optimizer_to\n",
    "from gen.utils.image_util import decompress_mask as util_decompress_mask\n",
    "import gen.constants as constants\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "from models.eval.eval import Eval\n",
    "from env.thor_env import ThorEnv\n",
    "from models.eval.eval_task import EvalTask\n",
    "from collections import defaultdict\n",
    "import logging\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UPDATE DATE & SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_task_json(args, task):\n",
    "    '''\n",
    "    load preprocessed json from disk\n",
    "    ''' \n",
    "    # e.g. /root/data_alfred/demo_generated/new_trajectories_debug_sampler_20200611/pick_two_obj_and_place-Watch-None-Dresser-205/trial_T20200611_235502_613792/traj_data.json\n",
    "    json_path = os.path.join(args.data, task['task'], 'traj_data.json')\n",
    "\n",
    "    with open(json_path) as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def decompress_mask(compressed_mask):\n",
    "    '''\n",
    "    decompress mask from json files\n",
    "    '''\n",
    "    mask = np.array(util_decompress_mask(compressed_mask))\n",
    "    mask = np.expand_dims(mask, axis=0)\n",
    "    return mask\n",
    "\n",
    "class CollectStates(EvalTask):\n",
    "\n",
    "    object_state_list = ['isToggled', 'isBroken', 'isFilledWithLiquid', 'isDirty',\n",
    "                  'isUsedUp', 'isCooked', 'ObjectTemperature', 'isSliced',\n",
    "                  'isOpen', 'isPickedUp', 'mass', 'receptacleObjectIds']\n",
    "\n",
    "    object_symbol_list = constants.OBJECTS\n",
    "\n",
    "    @classmethod\n",
    "    def get_object_list(cls, traj_data):\n",
    "        object_list = [ob['objectName'] for ob in traj_data['scene']['object_poses']]\n",
    "        for ob in object_list:\n",
    "            assert ob.split('_')[0] in constants.OBJECTS\n",
    "        return object_list\n",
    "\n",
    "    @classmethod\n",
    "    def get_object_states(cls, metadata):\n",
    "        object_states = defaultdict(dict)\n",
    "        for ob in metadata['objects']:\n",
    "            symbol = ob['name'].split('_')[0]\n",
    "            # assert symbol in cls.object_symbol_list\n",
    "            object_states[ob['name']]['symbol'] = symbol\n",
    "            object_states[ob['name']]['states'] = {state:ob[state] for state in cls.object_state_list}\n",
    "            object_states[ob['name']]['states']['parentReceptacles'] = ob['parentReceptacles'][0].split('|')[0] if ob['parentReceptacles'] is not None else None\n",
    "        return object_states\n",
    "\n",
    "    @classmethod    \n",
    "    def divide_objects_by_change(cls, object_states_curr, object_states_last):\n",
    "        objects_unchanged = []\n",
    "        objects_changed = []\n",
    "        for ob_name in object_states_last.keys():\n",
    "            changed = False\n",
    "            for state in cls.object_state_list + ['parentReceptacles']:\n",
    "                if state in object_states_last[ob_name]['states'].keys():\n",
    "                    if object_states_last[ob_name]['states'][state] != object_states_curr[ob_name]['states'][state]:\n",
    "                        changed = True\n",
    "            if changed == False:\n",
    "                objects_unchanged.append(ob_name)\n",
    "            else:\n",
    "                objects_changed.append(ob_name)\n",
    "        return objects_changed, objects_unchanged\n",
    "\n",
    "    @classmethod  \n",
    "    def get_unchanged_symbols(cls, objects_changed, objects_unchanged, symbol_set):\n",
    "        objects_symbols_changed = [ob_name.split('_')[0] for ob_name in objects_changed]\n",
    "        objects_symbols_unchanged = [ob_name.split('_')[0] for ob_name in objects_unchanged]\n",
    "        return list((set(objects_symbols_unchanged) - set(objects_symbols_changed)) & symbol_set)\n",
    "\n",
    "    @classmethod\n",
    "    def get_object_symbols_present_in_scene(cls, traj_data):\n",
    "        object_list = [ob['objectName'] for ob in traj_data['scene']['object_poses']]\n",
    "        extracted_symbols = [ob.split('_')[0] for ob in object_list]\n",
    "        # for symbol in extracted_symbols:\n",
    "        #     assert symbol in cls.object_symbol_list\n",
    "        return extracted_symbols\n",
    "\n",
    "    @classmethod\n",
    "    def get_receptacle_symbols_present_in_scene(cls, metadata):\n",
    "        receptacle_list = [ob['name'] for ob in metadata['objects'] if ob['receptacle']]\n",
    "        extracted_symbols = [ob.split('_')[0] for ob in receptacle_list]\n",
    "        return extracted_symbols\n",
    "\n",
    "    @classmethod\n",
    "    def get_visibility(cls, metadata, object_symbols, receptacle_symbols):\n",
    "        visible_objects = {ob:False for ob in object_symbols}\n",
    "        visible_receptacles = {recp:False for recp in receptacle_symbols}\n",
    "        for ob in metadata['objects']:\n",
    "            if ob['visible']:\n",
    "                symbol = ob['name'].split('_')[0]\n",
    "                if ob['receptacle']:\n",
    "                    visible_receptacles[symbol] = True\n",
    "                else:\n",
    "                    visible_objects[symbol] = True\n",
    "        return [ob for ob in visible_objects.keys() if visible_objects[ob]], [recp for recp in visible_receptacles.keys() if visible_receptacles[recp]]    \n",
    "\n",
    "    @classmethod\n",
    "    def has_interaction(cls, action):\n",
    "        '''\n",
    "        check if low-level action is interactive\n",
    "        '''\n",
    "        non_interact_actions = ['MoveAhead', 'Rotate', 'Look', '<<stop>>', '<<pad>>', '<<seg>>']\n",
    "        if any(a in action for a in non_interact_actions):\n",
    "            return False\n",
    "        else:\n",
    "            return True        \n",
    "\n",
    "    @classmethod\n",
    "    def evaluate(cls, args, r_idx, env, split_name, traj_data, success_log_entries, fail_log_entries, results, logger):\n",
    "\n",
    "        # setup scene\n",
    "        reward_type = 'dense'\n",
    "        cls.setup_scene(env, traj_data, r_idx, args, reward_type=reward_type)\n",
    "\n",
    "        # --------------- collect actions -----------------\n",
    "        # ground-truth low-level actions\n",
    "        # e.g. ['LookDown_15', 'MoveAhead_25', 'MoveAhead_25', ... '<<stop>>']\n",
    "        groundtruth_action_low = [a['discrete_action']['action'] for a in traj_data['plan']['low_actions']]\n",
    "        groundtruth_action_low.append(cls.STOP_TOKEN)\n",
    "\n",
    "        # get low-level action to high subgoal alignment\n",
    "        # get valid interaction per low-level action\n",
    "        # get interaction mask if any\n",
    "        end_action = {\n",
    "            'api_action': {'action': 'NoOp'},\n",
    "            'discrete_action': {'action': '<<stop>>', 'args': {}},\n",
    "            'high_idx': traj_data['plan']['high_pddl'][-1]['high_idx']\n",
    "        }\n",
    "        # e.g. [0,0,0, ... , 11], lenght = total T\n",
    "        groundtruth_subgoal_alignment = []\n",
    "        # e.g. [0,1,0, ... , 1], lenght = total T\n",
    "        groundtruth_valid_interacts = []\n",
    "        # len=num timestep with valid interact, np shape (1 , 300 , 300)\n",
    "        groundtruth_low_mask = []\n",
    "        for a in (traj_data['plan']['low_actions'] + [end_action]):\n",
    "            # high-level action index (subgoals)\n",
    "            groundtruth_subgoal_alignment.append(a['high_idx'])\n",
    "            # interaction validity\n",
    "            step_valid_interact = 1 if cls.has_interaction(a['discrete_action']['action']) else 0\n",
    "            groundtruth_valid_interacts.append(step_valid_interact)\n",
    "            # interaction mask values\n",
    "            if 'mask' in a['discrete_action']['args'].keys() and a['discrete_action']['args']['mask'] is not None:\n",
    "                groundtruth_low_mask.append(decompress_mask(a['discrete_action']['args']['mask']))\n",
    "\n",
    "        # ground-truth high-level subgoals\n",
    "        # e.g. ['GotoLocation', 'PickupObject', 'SliceObject', 'GotoLocation', 'PutObject', ... 'NoOp']\n",
    "        groundtruth_action_high = [a['discrete_action']['action'] for a in traj_data['plan']['high_pddl']]\n",
    "        \n",
    "        assert len(groundtruth_action_low) == len(groundtruth_subgoal_alignment) == len(groundtruth_valid_interacts)\n",
    "        assert len(groundtruth_action_high) == groundtruth_subgoal_alignment[-1] + 1\n",
    "        assert sum(groundtruth_valid_interacts) == len(groundtruth_low_mask)\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # --------------- execute actions -----------------\n",
    "\n",
    "        # initialize state dictionary for all timesteps\n",
    "        states = []\n",
    "\n",
    "        # get symbols and initial object states\n",
    "        event = env.last_event\n",
    "        obj_symbol_set = set(cls.get_object_symbols_present_in_scene(traj_data))\n",
    "        receptacle_symbol_set = set(cls.get_receptacle_symbols_present_in_scene(event.metadata))\n",
    "        object_states_last = cls.get_object_states(event.metadata) # includes receptacles\n",
    "\n",
    "        # loop through actions and execute them in the sim env\n",
    "        done, success = False, False\n",
    "        fails = 0\n",
    "        t = 0\n",
    "        reward = 0\n",
    "        action, mask = None, None\n",
    "        interact_ct = 0\n",
    "        high_idx = -1\n",
    "        while not done:            \n",
    "            # if last action was stop, break\n",
    "            if action == cls.STOP_TOKEN:\n",
    "                done = True\n",
    "                logging.info(\"predicted STOP\")\n",
    "                break\n",
    "  \n",
    "            if high_idx < groundtruth_subgoal_alignment[t]:\n",
    "                high_idx = groundtruth_subgoal_alignment[t]\n",
    "                new_subgoal = True\n",
    "            else:\n",
    "                new_subgoal = False\n",
    "            \n",
    "            # collect metadata states only\n",
    "            states.append({\n",
    "                'new_subgoal': new_subgoal,\n",
    "                'time_step': t,\n",
    "                'subgoal_step': groundtruth_subgoal_alignment[t],\n",
    "                'subgoal': groundtruth_action_high[groundtruth_subgoal_alignment[t]],\n",
    "                'objects_metadata': event.metadata['objects'],\n",
    "            })\n",
    "\n",
    "#             # transition to next subgoal\n",
    "#             if high_idx < groundtruth_subgoal_alignment[t]:\n",
    "#                 high_idx = groundtruth_subgoal_alignment[t]\n",
    "#                 object_states_curr = cls.get_object_states(event.metadata)\n",
    "#                 visible_objects, visible_receptacles = cls.get_visibility(event.metadata, obj_symbol_set, receptacle_symbol_set)\n",
    "#                 objects_changed, objects_unchanged = cls.divide_objects_by_change(object_states_curr, object_states_last)\n",
    "#                 states.append({\n",
    "#                     'time_step': t,\n",
    "#                     'raw_object_metadata': event.metadata['objects'],\n",
    "#                     'receptacle_states_delta': cls.get_unchanged_symbols(objects_changed, objects_unchanged, receptacle_symbol_set),\n",
    "#                     'object_states_delta': cls.get_unchanged_symbols(objects_changed, objects_unchanged, obj_symbol_set),\n",
    "#                     'visible_objects': visible_objects,\n",
    "#                     'visible_receptacles': visible_receptacles,\n",
    "#                     'subgoals': groundtruth_action_high[high_idx]\n",
    "#                 })\n",
    "#                 object_states_last = object_states_curr\n",
    "            \n",
    "            # collect groundtruth action and mask\n",
    "            # single string\n",
    "            action = groundtruth_action_low[t]\n",
    "            # expect (300, 300)\n",
    "            if groundtruth_valid_interacts[t]:\n",
    "                mask = groundtruth_low_mask[interact_ct][0]\n",
    "                interact_ct += 1\n",
    "            else:\n",
    "                mask = None\n",
    "\n",
    "            # interact with the env\n",
    "            t_success, event, _, err, _ = env.va_interact(action, interact_mask=mask, smooth_nav=args.smooth_nav, debug=args.debug)\n",
    "            if not t_success:\n",
    "                fails += 1\n",
    "                if fails >= args.max_fails:\n",
    "                    logging.info(\"Interact API failed %d times\" % fails + \"; latest error '%s'\" % err)\n",
    "                    break            \n",
    " \n",
    "            # next time-step\n",
    "            t_reward, t_done = env.get_transition_reward()\n",
    "            reward += t_reward\n",
    "            t += 1\n",
    "        \n",
    "        # make sure we have used all masks\n",
    "        assert interact_ct == sum(groundtruth_valid_interacts)\n",
    "        \n",
    "        # check if goal was satisfied\n",
    "        goal_satisfied = env.get_goal_satisfied()\n",
    "        if goal_satisfied:\n",
    "            print(\"Goal Reached\")\n",
    "            success = True\n",
    "        assert success       \n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # ------debug execution success rate --------------\n",
    "        if args.debug:\n",
    "\n",
    "            # goal_conditions\n",
    "            pcs = env.get_goal_conditions_met()\n",
    "            goal_condition_success_rate = pcs[0] / float(pcs[1])\n",
    "\n",
    "            # SPL\n",
    "            path_len_weight = len(traj_data['plan']['low_actions'])\n",
    "            s_spl = (1 if goal_satisfied else 0) * min(1., path_len_weight / float(t))\n",
    "            pc_spl = goal_condition_success_rate * min(1., path_len_weight / float(t))\n",
    "\n",
    "            # path length weighted SPL\n",
    "            plw_s_spl = s_spl * path_len_weight\n",
    "            plw_pc_spl = pc_spl * path_len_weight\n",
    "            \n",
    "            \n",
    "            log_entry = {'trial': traj_data['task_id'],\n",
    "                        'type': traj_data['task_type'],\n",
    "                        'repeat_idx': int(r_idx) if r_idx else None,\n",
    "                        'goal_instr': goal_instr,\n",
    "                        'completed_goal_conditions': int(pcs[0]),\n",
    "                        'total_goal_conditions': int(pcs[1]),\n",
    "                        'goal_condition_success': float(goal_condition_success_rate),\n",
    "                        'success_spl': float(s_spl),\n",
    "                        'path_len_weighted_success_spl': float(plw_s_spl),\n",
    "                        'goal_condition_spl': float(pc_spl),\n",
    "                        'path_len_weighted_goal_condition_spl': float(plw_pc_spl),\n",
    "                        'path_len_weight': int(path_len_weight),\n",
    "                        'reward': float(reward)}\n",
    "            if success:\n",
    "                success_log_entries.append(log_entry)\n",
    "            else:\n",
    "                fail_log_entries.append(log_entry)\n",
    "\n",
    "            # overall results\n",
    "            results['all'] = cls.get_metrics(successes, failures)\n",
    "\n",
    "            logging.info(\"-------------\")\n",
    "            logging.info(\"SR: %d/%d = %.3f\" % (results['all']['success']['num_successes'],\n",
    "                                        results['all']['success']['num_evals'],\n",
    "                                        results['all']['success']['success_rate']))\n",
    "            logging.info(\"GC: %d/%d = %.3f\" % (results['all']['goal_condition_success']['completed_goal_conditions'],\n",
    "                                        results['all']['goal_condition_success']['total_goal_conditions'],\n",
    "                                        results['all']['goal_condition_success']['goal_condition_success_rate']))\n",
    "            logging.info(\"PLW SR: %.3f\" % (results['all']['path_length_weighted_success_rate']))\n",
    "            logging.info(\"PLW GC: %.3f\" % (results['all']['path_length_weighted_goal_condition_success_rate']))\n",
    "            logging.info(\"-------------\")\n",
    "\n",
    "            # task type specific results\n",
    "            task_types = ['pick_and_place_simple', 'pick_clean_then_place_in_recep', 'pick_heat_then_place_in_recep',\n",
    "                        'pick_cool_then_place_in_recep', 'pick_two_obj_and_place', 'look_at_obj_in_light',\n",
    "                        'pick_and_place_with_movable_recep']\n",
    "            for task_type in task_types:\n",
    "                task_successes = [s for s in (list(successes)) if s['type'] == task_type]\n",
    "                task_failures = [f for f in (list(failures)) if f['type'] == task_type]\n",
    "                if len(task_successes) > 0 or len(task_failures) > 0:\n",
    "                    results[task_type] = cls.get_metrics(task_successes, task_failures)\n",
    "                else:\n",
    "                    results[task_type] = {}            \n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # ------save the object states out --------------\n",
    "        logging.info(\"Goal Reached\")\n",
    "        outpath = os.path.join(traj_data['raw_root'], 'metadata_states.json')\n",
    "        logging.info('saving to outpath: {}'.format(outpath))\n",
    "        with open(outpath, 'w') as f:\n",
    "            json.dump(states, f)\n",
    "        logging.info(\"----------------------------------------\")\n",
    "\n",
    "        return states, outpath\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    TIME_NOW = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "    log_file_path = os.path.join(args.data, f'collect_demo_obj_states_T{TIME_NOW}.log')\n",
    "    hdlr = logging.FileHandler(log_file_path)\n",
    "    logger.addHandler(hdlr)\n",
    "    print (f'Logger is writing to {log_file_path}')\n",
    "\n",
    "    # start sim env\n",
    "    env = ThorEnv()\n",
    "    \n",
    "    # load splits\n",
    "    with open(args.raw_splits) as f:\n",
    "        raw_splits = json.load(f)\n",
    "    print(f'Raw Splits are : {raw_splits.keys()}')\n",
    "\n",
    "    # no language annotation available\n",
    "    r_idx = None\n",
    "\n",
    "    # book keeping -- some planner generated traj can still fail on execution\n",
    "    # save to files\n",
    "    failed_splits = {split_name:[] for split_name in raw_splits.keys()}\n",
    "    out_splits = {split_name:[] for split_name in raw_splits.keys()}\n",
    "    # report successes thus far (used in debugging only)\n",
    "    success_log_entries = {split_name:[] for split_name in raw_splits.keys()}\n",
    "    fail_log_entries = {split_name:[] for split_name in raw_splits.keys()}\n",
    "    tot_ct = {split_name:len(raw_splits[split_name]) for split_name in raw_splits.keys()}\n",
    "    results = {split_name:{} for split_name in raw_splits.keys()}\n",
    "\n",
    "    # loop through splits\n",
    "    print ('-----------START COLLECTING OBJECT STATES FROM RAW TRAJECTORIES-----------')\n",
    "    for split_name in raw_splits.keys():\n",
    "        tasks = [task for task in raw_splits[split_name]]\n",
    "        split_count = 0\n",
    "        print(f'Split {split_name} starts object states collection')\n",
    "        print(f'Tasks: {tasks}')\n",
    "        for task in progressbar.progressbar(tasks):\n",
    "            traj_data = load_task_json(args, task)\n",
    "            traj_data['raw_root'] = os.path.join(args.data, task['task'])\n",
    "            split_count += 1\n",
    "            logger.info('-----------------')\n",
    "            logger.info(f'Split {split_name}: {split_count}/{tot_ct[split_name]} task')\n",
    "            logger.info(f'Task Root: {traj_data[\"raw_root\"]}.')\n",
    "            logger.info(f'Task Type: {traj_data[\"task_type\"]}.')\n",
    "            print(f'Processing {traj_data[\"raw_root\"]}')\n",
    "            try:\n",
    "                _, _ = CollectStates.evaluate(args, r_idx, env, split_name, traj_data, success_log_entries, fail_log_entries, results, logger)\n",
    "                print(f'Task succeeds to collect object state.')\n",
    "                out_splits[split_name].append({'task': task[\"task\"]}) # '<goal type>/<task_id>'\n",
    "            except Exception as e:\n",
    "                raise e\n",
    "                failed_splits[split_name].append({'task': task[\"task\"]})\n",
    "                print(f'Task fails to collect object state.')\n",
    "        print(f'Split {split_name} object states collection results: successes={len(out_splits[split_name])}, fails={len(failed_splits[split_name])}, total={tot_ct[split_name]}')\n",
    "                                       \n",
    "    # save success splits\n",
    "    # /root/data_alfred/splits/\n",
    "    split_file_dir = '/'.join(args.raw_splits.split('/')[:-1])\n",
    "    # demo_june13_raw.json\n",
    "    split_file_name = args.raw_splits.split('/')[-1] \n",
    "    # /root/data_alfred/splits/demo_june13.json\n",
    "    out_splits_path = os.path.join(split_file_dir, split_file_name.replace('_raw.json', '.json'))\n",
    "    with open(out_splits_path, 'w') as f:\n",
    "        json.dump(out_splits, f)\n",
    "    print(f'Task IDs with object states successfully collected are saved to {out_splits_path}')\n",
    "\n",
    "    # save failed splits if debuggin\n",
    "    if args.debug:\n",
    "        # save failed splits\n",
    "        # /root/data_alfred/splits/demo_june13_failed.json\n",
    "        failed_splits_path = os.path.join(split_file_dir, split_file_name.replace('_raw.json', '_failed.json'))\n",
    "        with open(failed_splits_path, 'w') as f:\n",
    "            json.dump(failed_splits, f)\n",
    "        print(f'Task IDs that failed object states collection are saved to {failed_splits_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args():\n",
    "    pass\n",
    "\n",
    "args.data = '/root/data_alfred/demo_generated/new_trajectories_T20200615_195126_390279'\n",
    "args.raw_splits = '/root/data_alfred/splits/demo_T20200615_195126_390279_raw.json'\n",
    "args.debug = False\n",
    "\n",
    "args.reward_config = 'models/config/rewards.json'\n",
    "args.max_fails = 10\n",
    "args.subgoals = \"\"\n",
    "args.smooth_nav = False\n",
    "args.reward_config = os.path.join(os.environ['ALFRED_ROOT'], args.reward_config)\n",
    "\n",
    "# args.gpu = False\n",
    "\n",
    "# args.num_threads = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logger is writing to /root/data_alfred/demo_generated/new_trajectories_T20200615_195126_390279/collect_demo_obj_states_T20200616_080457_936234.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "N/A% (0 of 1) |                          | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ThorEnv started.\n",
      "Raw Splits are : dict_keys(['demo'])\n",
      "-----------START COLLECTING OBJECT STATES FROM RAW TRAJECTORIES-----------\n",
      "Split demo starts object states collection\n",
      "Tasks: [{'task': 'pick_two_obj_and_place-Watch-None-Dresser-205/trial_T20200615_195304_439792'}]\n",
      "Processing /root/data_alfred/demo_generated/new_trajectories_T20200615_195126_390279/pick_two_obj_and_place-Watch-None-Dresser-205/trial_T20200615_195304_439792\n",
      "Resetting ThorEnv\n",
      "Goal Reached\n",
      "Task succeeds to collect object state.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b3f47c9a9b7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-122374d3ff06>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    366\u001b[0m                 \u001b[0mout_splits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'task'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"task\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# '<goal type>/<task_id>'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m                 \u001b[0mfailed_splits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'task'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"task\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Task fails to collect object state.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-122374d3ff06>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCollectStates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraj_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuccess_log_entries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfail_log_entries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Task succeeds to collect object state.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m                 \u001b[0mout_splits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'task'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"task\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# '<goal type>/<task_id>'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

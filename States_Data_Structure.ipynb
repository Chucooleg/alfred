{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from vocab import Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to run just a single example\n",
    "states_path = '/root/data_alfred/json_feat_2.1.0/pick_and_place_simple-TennisRacket-None-Bed-303/trial_T20190906_193617_277654/pp/metadata_states.json'\n",
    "\n",
    "with open(states_path, 'r') as f:\n",
    "    saved_states = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_state_types = ['isToggled', 'isBroken', 'isFilledWithLiquid', 'isDirty',\n",
    "                      'isUsedUp', 'isCooked', 'ObjectTemperature', 'isSliced',\n",
    "                      'isOpen', 'isPickedUp', 'mass', 'receptacleObjectIds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_vocab = dict()\n",
    "object_vocab['object_type'] = Vocab(['<<pad>>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_object_states(obj, required_state_types):\n",
    "    o_states = {}\n",
    "    for state_typ in required_state_types:\n",
    "        if state_typ in obj.keys():\n",
    "            o_states[state_typ] = obj[state_typ]\n",
    "        else:\n",
    "            o_states[state_typ] = None\n",
    "    return o_states\n",
    "\n",
    "def detect_state_change(last_obj_states, curr_obj_states, objectId_list):\n",
    "    state_change = []\n",
    "    for obj_Id in objectId_list:\n",
    "        if (not obj_Id in last_obj_states) and (not obj_Id in curr_obj_states):\n",
    "            state_change.append(False)\n",
    "        elif not obj_Id in last_obj_states:\n",
    "            state_change.append(True)\n",
    "        elif not obj_Id in curr_obj_states:\n",
    "            raise Exception('Objects should always appear in next time step.')\n",
    "        else:\n",
    "            if last_obj_states[obj_Id] == curr_obj_states[obj_Id]:\n",
    "                state_change.append(False)\n",
    "            else:\n",
    "                state_change.append(True)\n",
    "    return state_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_type_state_change(instance_state_change, object_instance_list_sorted, object_type_list_sorted):\n",
    "    state_change = []\n",
    "    \n",
    "    curr_typ = object_instance_list_sorted[0].split('|')[0]\n",
    "    changes = []\n",
    "    for i, instance_name in enumerate(object_instance_list_sorted):\n",
    "        instance_typ = instance_name.split('|')[0]\n",
    "        if instance_typ != curr_typ:\n",
    "            state_change.append(True in changes)\n",
    "            changes = []\n",
    "            curr_typ = instance_typ\n",
    "        changes.append(instance_state_change[i])\n",
    "            \n",
    "    # don't forget about last typ!\n",
    "    state_change.append(int(True in changes))\n",
    "    assert len(state_change) == len(object_type_list_sorted)\n",
    "    return state_change\n",
    "\n",
    "def detect_type_visibility(instance_visible, object_instance_list_sorted, object_type_list_sorted):\n",
    "    type_visible = []\n",
    "    \n",
    "    curr_typ = object_instance_list_sorted[0].split('|')[0]\n",
    "    visible = []\n",
    "    for i, instance_name in enumerate(object_instance_list_sorted):\n",
    "        instance_typ = instance_name.split('|')[0]\n",
    "        if instance_typ != curr_typ:\n",
    "            type_visible.append(True in visible)\n",
    "            visible = []\n",
    "            curr_typ = instance_typ\n",
    "        visible.append(instance_visible[i])\n",
    "            \n",
    "    # don't forget about last typ!\n",
    "    type_visible.append(int(True in visible))\n",
    "    assert len(type_visible) == len(object_type_list_sorted)\n",
    "    return type_visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_states(saved_states):\n",
    "    # shift all the states to the last time step\n",
    "    shifted_states = [{} for _ in range(len(saved_states))]\n",
    "\n",
    "    for t, state in enumerate(saved_states):\n",
    "        new_state = {k:v for k,v in state.items() if k != 'objects_metadata'}\n",
    "        if t < len(saved_states) - 1:\n",
    "            new_state['objects_metadata'] = saved_states[t+1]['objects_metadata']\n",
    "        elif t == len(saved_states) - 1:\n",
    "            new_state['objects_metadata'] = saved_states[t]['objects_metadata']\n",
    "        shifted_states[t] = new_state\n",
    "        \n",
    "    return shifted_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_states_for_model(shifted_states, saved_states, root):\n",
    "\n",
    "    objectId_list = sorted([o['objectId'].lower() for o in shifted_states[-1]['objects_metadata']])\n",
    "    objectTyp_list = sorted(set([o.split('|')[0].lower() for o in objectId_list]))\n",
    "    num_subgoals = len(set([s['subgoal_step'] for s in shifted_states]))\n",
    "\n",
    "    try:\n",
    "        feat = {\n",
    "            'subgoal': [[] for _ in range(num_subgoals)],\n",
    "            'subgoal_i': [[] for _ in range(num_subgoals)],\n",
    "            'subgoal_t': [[] for _ in range(num_subgoals)],\n",
    "            'overall_t': [[] for _ in range(num_subgoals)],\n",
    "\n",
    "            'objectInstanceList': objectId_list,\n",
    "            'objectInstanceList_TypeNum': object_vocab['object_type'].word2index([o.split('|')[0] for o in objectId_list], train=True),\n",
    "            'instance_visibile': [[] for _ in range(num_subgoals)], # [subgoal_i][subgoal timestep] = [T/F for ob in objectId_list]\n",
    "            'instance_state_change': [[] for _ in range(num_subgoals)],\n",
    "\n",
    "            'objectTypeList': objectTyp_list,\n",
    "            'objectTypeList_TypeNum': object_vocab['object_type'].word2index(objectTyp_list, train=True),\n",
    "            'type_visibile': [[] for _ in range(num_subgoals)], # [subgoal_i][subgoal timestep] = [T/F for ob in objectTyp_list]\n",
    "            'type_state_change': [[] for _ in range(num_subgoals)]\n",
    "        }\n",
    "    except:\n",
    "        import pdb; pdb.set_trace()\n",
    "\n",
    "    last_obj_states = {obj['objectId'].lower():get_object_states(obj, object_state_types) for obj in saved_states[0]['objects_metadata']}\n",
    "    for t, state in enumerate(shifted_states):\n",
    "\n",
    "        subgoal_i = state['subgoal_step']\n",
    "        subgoal = state['subgoal']\n",
    "\n",
    "        if state['new_subgoal']:\n",
    "            subgoal_t = 0\n",
    "\n",
    "        feat['subgoal_i'][subgoal_i].append(subgoal_i)\n",
    "        feat['subgoal_t'][subgoal_i].append(subgoal_t)\n",
    "        feat['subgoal'][subgoal_i].append(subgoal)\n",
    "        feat['overall_t'][subgoal_i].append(t)\n",
    "\n",
    "        # get state change\n",
    "        curr_obj_states = {obj['objectId'].lower():get_object_states(obj, object_state_types) for obj in state['objects_metadata']}\n",
    "        \n",
    "        # list same order as objectId_list\n",
    "        state_change = detect_state_change(last_obj_states, curr_obj_states, objectId_list)\n",
    "        last_obj_states = curr_obj_states\n",
    "\n",
    "        feat['instance_state_change'][subgoal_i].append(state_change)\n",
    "    \n",
    "        # get visibility\n",
    "        visible = [False for _ in objectId_list]\n",
    "        for ob in state['objects_metadata']:\n",
    "            pos = objectId_list.index(ob['objectId'].lower())\n",
    "            visible[pos] = ob['visible']\n",
    "        feat['instance_visibile'][subgoal_i].append(visible)\n",
    "\n",
    "        # get type state change\n",
    "        type_state_change = detect_type_state_change(state_change, objectId_list, objectTyp_list)\n",
    "        feat['type_state_change'][subgoal_i].append(type_state_change)\n",
    "\n",
    "        # get type visibility\n",
    "        type_visible = detect_type_visibility(visible, objectId_list, objectTyp_list)\n",
    "        feat['type_visibile'][subgoal_i].append(type_visible)\n",
    "\n",
    "        subgoal_t += 1\n",
    "        \n",
    "    return feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success paths =  6505\n",
      "failed paths =  69\n"
     ]
    }
   ],
   "source": [
    "date = '20200511'\n",
    "split_name = 'train'\n",
    "\n",
    "with open('/root/data_alfred/splits/collect_states_{}_{}_notebook_success_paths.json'.format(date, split_name), 'r') as f:\n",
    "    success_outpaths = json.load(f)\n",
    "    \n",
    "len(success_outpaths)\n",
    "\n",
    "with open('/root/data_alfred/splits/collect_states_{}_{}_notebook_failed_roots.json'.format(date, split_name), 'r') as f:\n",
    "    failed_roots = json.load(f)\n",
    "    \n",
    "print('success paths = ', len(success_outpaths))\n",
    "print('failed paths = ', len(failed_roots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6505\n"
     ]
    }
   ],
   "source": [
    "extract_feat_dum = []\n",
    "extract_feat_outpaths = []\n",
    "\n",
    "for metadata_outpath in success_outpaths:\n",
    "    \n",
    "    with open(metadata_outpath, 'r') as f:\n",
    "        saved_states = json.load(f)\n",
    "        \n",
    "    root = metadata_outpath[:metadata_outpath.index('pp/')]\n",
    "    \n",
    "    shifted_states = shift_states(saved_states)\n",
    "    extract_feat = extract_states_for_model(shifted_states, saved_states, root)\n",
    "    extract_feat['metadata_path'] = metadata_outpath\n",
    "    extract_feat['root'] = root\n",
    "    \n",
    "    extract_feat_outpath = metadata_outpath.replace('/metadata_states.json', '/extracted_feature_states.json')\n",
    "    with open(extract_feat_outpath, 'w') as f:\n",
    "        json.dump(extract_feat ,f)\n",
    "    \n",
    "    extract_feat_outpaths.append(extract_feat_outpath)\n",
    "    extract_feat_dum.append(extract_feat)\n",
    "    \n",
    "print(len(extract_feat_dum))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '20200513'\n",
    "with open('/root/data_alfred/splits/extract_feat_states_{}_{}_notebook_outpaths.json'.format(date, split_name), 'w') as f:\n",
    "    json.dump(extract_feat_outpaths, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VALID SEEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success paths =  249\n",
      "failed paths =  2\n"
     ]
    }
   ],
   "source": [
    "date = '20200511'\n",
    "split_name = 'valid_seen'\n",
    "\n",
    "with open('/root/data_alfred/splits/collect_states_{}_{}_notebook_success_paths.json'.format(date, split_name), 'r') as f:\n",
    "    success_outpaths = json.load(f)\n",
    "    \n",
    "len(success_outpaths)\n",
    "\n",
    "with open('/root/data_alfred/splits/collect_states_{}_{}_notebook_failed_roots.json'.format(date, split_name), 'r') as f:\n",
    "    failed_roots = json.load(f)\n",
    "    \n",
    "print('success paths = ', len(success_outpaths))\n",
    "print('failed paths = ', len(failed_roots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249\n"
     ]
    }
   ],
   "source": [
    "extract_feat_dum = []\n",
    "extract_feat_outpaths = []\n",
    "\n",
    "for metadata_outpath in success_outpaths:\n",
    "    \n",
    "    with open(metadata_outpath, 'r') as f:\n",
    "        saved_states = json.load(f)\n",
    "        \n",
    "    root = metadata_outpath[:metadata_outpath.index('pp/')]\n",
    "    \n",
    "    shifted_states = shift_states(saved_states)\n",
    "    extract_feat = extract_states_for_model(shifted_states, saved_states, root)\n",
    "    extract_feat['metadata_path'] = metadata_outpath\n",
    "    extract_feat['root'] = root\n",
    "    \n",
    "    extract_feat_outpath = metadata_outpath.replace('/metadata_states.json', '/extracted_feature_states.json')\n",
    "    with open(extract_feat_outpath, 'w') as f:\n",
    "        json.dump(extract_feat ,f)\n",
    "    \n",
    "    extract_feat_outpaths.append(extract_feat_outpath)\n",
    "    extract_feat_dum.append(extract_feat)\n",
    "    \n",
    "print(len(extract_feat_dum))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '20200513'\n",
    "with open('/root/data_alfred/splits/extract_feat_states_{}_{}_notebook_outpaths.json'.format(date, split_name), 'w') as f:\n",
    "    json.dump(extract_feat_outpaths, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VALID UNSEEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success paths =  254\n",
      "failed paths =  1\n"
     ]
    }
   ],
   "source": [
    "date = '20200511'\n",
    "split_name = 'valid_unseen'\n",
    "\n",
    "with open('/root/data_alfred/splits/collect_states_{}_{}_notebook_success_paths.json'.format(date, split_name), 'r') as f:\n",
    "    success_outpaths = json.load(f)\n",
    "    \n",
    "len(success_outpaths)\n",
    "\n",
    "with open('/root/data_alfred/splits/collect_states_{}_{}_notebook_failed_roots.json'.format(date, split_name), 'r') as f:\n",
    "    failed_roots = json.load(f)\n",
    "    \n",
    "print('success paths = ', len(success_outpaths))\n",
    "print('failed paths = ', len(failed_roots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254\n"
     ]
    }
   ],
   "source": [
    "extract_feat_dum = []\n",
    "extract_feat_outpaths = []\n",
    "\n",
    "for metadata_outpath in success_outpaths:\n",
    "    \n",
    "    with open(metadata_outpath, 'r') as f:\n",
    "        saved_states = json.load(f)\n",
    "        \n",
    "    root = metadata_outpath[:metadata_outpath.index('pp/')]\n",
    "    \n",
    "    shifted_states = shift_states(saved_states)\n",
    "    extract_feat = extract_states_for_model(shifted_states, saved_states, root)\n",
    "    extract_feat['metadata_path'] = metadata_outpath\n",
    "    extract_feat['root'] = root\n",
    "    \n",
    "    extract_feat_outpath = metadata_outpath.replace('/metadata_states.json', '/extracted_feature_states.json')\n",
    "    with open(extract_feat_outpath, 'w') as f:\n",
    "        json.dump(extract_feat ,f)\n",
    "    \n",
    "    extract_feat_outpaths.append(extract_feat_outpath)\n",
    "    extract_feat_dum.append(extract_feat)\n",
    "    \n",
    "print(len(extract_feat_dum))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '20200513'\n",
    "with open('/root/data_alfred/splits/extract_feat_states_{}_{}_notebook_outpaths.json'.format(date, split_name), 'w') as f:\n",
    "    json.dump(extract_feat_outpaths, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE OBJECT VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save vocab in dout path\n",
    "import os\n",
    "vocab_dout_path = os.path.join('/root/data_alfred/json_feat_2.1.0', '%s.vocab' % 'objects')\n",
    "torch.save(object_vocab, vocab_dout_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vocab(109)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_vocab['object_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

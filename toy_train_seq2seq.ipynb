{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['ALFRED_ROOT'] = '/home/hoyeung/alfred/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.join(os.environ['ALFRED_ROOT']))\n",
    "sys.path.append(os.path.join(os.environ['ALFRED_ROOT'], 'models'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser\n",
    "import torch\n",
    "import pprint\n",
    "import json\n",
    "from data.preprocess import Dataset\n",
    "from importlib import import_module\n",
    "from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser\n",
    "from models.utils.helper_utils import optimizer_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nn.vnn as vnn\n",
    "import collections\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from model.seq2seq import Module as Base\n",
    "from models.utils.metric import compute_f1, compute_exact\n",
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser\n",
    "# parser = ArgumentParser(formatter_class=ArgumentDefaultsHelpFormatter)\n",
    "\n",
    "class args:\n",
    "    pass\n",
    "\n",
    "# settings\n",
    "# parser.add_argument('--seed', help='random seed', default=123, type=int)\n",
    "# parser.add_argument('--data', help='dataset folder', default='data/json_feat_2.1.0')\n",
    "# parser.add_argument('--splits', help='json file containing train/dev/test splits', default='splits/oct21.json')\n",
    "# parser.add_argument('--preprocess', help='store preprocessed data to json files', action='store_true')\n",
    "# parser.add_argument('--pp_folder', help='folder name for preprocessed data', default='pp')\n",
    "# parser.add_argument('--save_every_epoch', help='save model after every epoch (warning: consumes a lot of space)', action='store_true')\n",
    "# parser.add_argument('--model', help='model to use', default='seq2seq_im')\n",
    "# parser.add_argument('--gpu', help='use gpu', action='store_true')\n",
    "# parser.add_argument('--dout', help='where to save model', default='exp/model:{model}')\n",
    "# parser.add_argument('--resume', help='load a checkpoint')\n",
    "args.seed = 123\n",
    "args.data = 'data/json_feat_2.1.0'\n",
    "args.splits = 'splits/oct21.json'\n",
    "args.preprocess = False #!\n",
    "args.pp_folder = 'pp'\n",
    "args.save_every_epoch = False #!\n",
    "args.model = 'seq2seq_im'\n",
    "args.gpu = True\n",
    "args.dout = 'exp/model:seq2seq_im'\n",
    "args.resume = False #!\n",
    "\n",
    "\n",
    "# hyper parameters\n",
    "# parser.add_argument('--batch', help='batch size', default=8, type=int)\n",
    "# parser.add_argument('--epoch', help='number of epochs', default=20, type=int)\n",
    "# parser.add_argument('--lr', help='optimizer learning rate', default=1e-4, type=float)\n",
    "# parser.add_argument('--decay_epoch', help='num epoch to adjust learning rate', default=10, type=int)\n",
    "# parser.add_argument('--dhid', help='hidden layer size', default=512, type=int)\n",
    "# parser.add_argument('--dframe', help='image feature vec size', default=2500, type=int)\n",
    "# parser.add_argument('--demb', help='language embedding size', default=100, type=int)\n",
    "# parser.add_argument('--pframe', help='image pixel size (assuming square shape eg: 300x300)', default=300, type=int)\n",
    "# parser.add_argument('--mask_loss_wt', help='weight of mask loss', default=1., type=float)\n",
    "# parser.add_argument('--action_loss_wt', help='weight of action loss', default=1., type=float)\n",
    "# parser.add_argument('--subgoal_aux_loss_wt', help='weight of subgoal completion predictor', default=0., type=float)\n",
    "# parser.add_argument('--pm_aux_loss_wt', help='weight of progress monitor', default=0., type=float)\n",
    "args.batch = 8\n",
    "args.epoch = 20\n",
    "args.lr = 1e-4\n",
    "args.decay_epoch = 10\n",
    "args.dhid = 512\n",
    "args.dframe = 2500\n",
    "args.demb = 100\n",
    "args.pframe = 300\n",
    "args.mask_loss_wt = 1.\n",
    "args.action_loss_wt = 1.\n",
    "args.subgoal_aux_loss_wt = 0.\n",
    "args.pm_aux_loss_wt = 0.\n",
    "\n",
    "\n",
    "\n",
    "# dropouts\n",
    "# parser.add_argument('--zero_goal', help='zero out goal language', action='store_true')\n",
    "# parser.add_argument('--zero_instr', help='zero out step-by-step instr language', action='store_true')\n",
    "# parser.add_argument('--lang_dropout', help='dropout rate for language (goal + instr)', default=0., type=float)\n",
    "# parser.add_argument('--input_dropout', help='dropout rate for concatted input feats', default=0., type=float)\n",
    "# parser.add_argument('--vis_dropout', help='dropout rate for Resnet feats', default=0.3, type=float)\n",
    "# parser.add_argument('--hstate_dropout', help='dropout rate for LSTM hidden states during unrolling', default=0.3, type=float)\n",
    "# parser.add_argument('--attn_dropout', help='dropout rate for attention', default=0., type=float)\n",
    "# parser.add_argument('--actor_dropout', help='dropout rate for actor fc', default=0., type=float)\n",
    "args.zero_goal = False #!\n",
    "args.zero_instr = False #!\n",
    "args.act_dropout = 0.\n",
    "args.lang_dropout = 0.\n",
    "args.input_dropout = 0.\n",
    "args.vis_dropout = 0.3\n",
    "args.hstate_dropout = 0.3\n",
    "args.attn_dropout = 0.\n",
    "args.actor_dropout = 0.\n",
    "\n",
    "\n",
    "# other settings\n",
    "# parser.add_argument('--dec_teacher_forcing', help='use gpu', action='store_true')\n",
    "# parser.add_argument('--temp_no_history', help='use gpu', action='store_true')\n",
    "args.dec_teacher_forcing = False #!\n",
    "args.temp_no_history = False #!\n",
    "\n",
    "\n",
    "# debugging\n",
    "# parser.add_argument('--fast_epoch', help='fast epoch during debugging', action='store_true')\n",
    "# parser.add_argument('--dataset_fraction', help='use fraction of the dataset for debugging (0 indicates full size)', default=0, type=int)\n",
    "args.fast_epoch = False #!\n",
    "args.dataset_fraction = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.splits = 'data/splits/oct21.json'\n",
    "args.dec_teacher_forcing = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fdd9f4c5630>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.out  exp/model:seq2seq_im\n"
     ]
    }
   ],
   "source": [
    "# make output dir\n",
    "if not os.path.isdir(args.dout):\n",
    "    os.makedirs(args.dout)\n",
    "\n",
    "print('args.out ', args.dout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tests_seen': 1533,\n",
      " 'tests_unseen': 1529,\n",
      " 'train': 21023,\n",
      " 'valid_seen': 820,\n",
      " 'valid_unseen': 821}\n"
     ]
    }
   ],
   "source": [
    "# load train/valid/tests splits\n",
    "with open(args.splits) as f:\n",
    "    splits = json.load(f)\n",
    "    pprint.pprint({k: len(v) for k, v in splits.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word': Vocab(2360), 'action_low': Vocab(15), 'action_high': Vocab(93)}\n"
     ]
    }
   ],
   "source": [
    "# preprocess and save\n",
    "if args.preprocess:\n",
    "    print(\"\\nPreprocessing dataset and saving to %s folders ... This will take a while. Do this once as required.\" % args.pp_folder)\n",
    "    dataset = Dataset(args, None)\n",
    "    dataset.preprocess_splits(splits)\n",
    "    vocab = torch.load(os.path.join(args.dout, \"%s.vocab\" % args.pp_folder))\n",
    "else:\n",
    "    vocab = torch.load(os.path.join(args.data, \"%s.vocab\" % args.pp_folder))\n",
    "    \n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqNL(Base):\n",
    "\n",
    "    def __init__(self, args, vocab):\n",
    "        '''\n",
    "        Seq2Seq agent\n",
    "        '''\n",
    "        super(NLSeq2Seq, self).__init__(args, vocab)\n",
    "\n",
    "        # encoder and self-attention\n",
    "        self.enc = nn.LSTM(args.demb, args.dhid, bidirectional=True, batch_first=True)\n",
    "        self.enc_att = vnn.SelfAttn(args.dhid*2)\n",
    "\n",
    "#         # frame mask decoder\n",
    "#         decoder = vnn.ConvFrameMaskDecoderProgressMonitor if self.subgoal_monitoring else vnn.ConvFrameMaskDecoder\n",
    "#         self.dec = decoder(self.emb_action_low, args.dframe, 2*args.dhid,\n",
    "#                            pframe=args.pframe,\n",
    "#                            attn_dropout=args.attn_dropout,\n",
    "#                            hstate_dropout=args.hstate_dropout,\n",
    "#                            actor_dropout=args.actor_dropout,\n",
    "#                            input_dropout=args.input_dropout,\n",
    "#                            teacher_forcing=args.dec_teacher_forcing)\n",
    "\n",
    "        self.dec = ???\n",
    "\n",
    "        # dropouts\n",
    "#         self.lang_dropout = nn.Dropout(args.lang_dropout, inplace=True)\n",
    "        self.input_dropout = nn.Dropout(args.input_dropout)\n",
    "\n",
    "        # internal states\n",
    "        self.state_t = None\n",
    "        self.e_t = None\n",
    "        self.test_mode = False\n",
    "\n",
    "        # bce reconstruction loss\n",
    "        self.lang_loss = ???\n",
    "#         self.mse_loss = torch.nn.MSELoss(reduction='none')\n",
    "\n",
    "        # paths\n",
    "        self.root_path = os.getcwd()\n",
    "\n",
    "        # params\n",
    "        self.max_subgoals = 25\n",
    "\n",
    "        # reset model\n",
    "        self.reset()\n",
    "\n",
    "#     def iterate(self, data, batch_size):\n",
    "#         '''\n",
    "#         breaks dataset into batch_size chunks for training\n",
    "#         '''\n",
    "#         for i in trange(0, len(data), batch_size, desc='batch'):\n",
    "#             tasks = data[i:i+batch_size]\n",
    "#             batch = [self.load_task_json(task) for task in tasks]\n",
    "#             feat = self.featurize(batch)\n",
    "#             yield batch, feat\n",
    "        \n",
    "    def featurize(batch):\n",
    "        '''tensoroze and pad batch input'''\n",
    "    \n",
    "        device = torch.device('cuda') if self.args.gpu else torch.device('cpu')\n",
    "        feat = collections.defaultdict(list)\n",
    "    \n",
    "        for ex in batch:\n",
    "            \n",
    "            #########\n",
    "            # outputs\n",
    "            #########\n",
    "            \n",
    "            # serialize segments\n",
    "            self.serialize_lang_action(ex)\n",
    "            \n",
    "            # goal and instr language\n",
    "            lang_goal, lang_instr = ex['num']['lang_goal'], ex['num']['lang_instr']\n",
    "            \n",
    "            # zero inputs if specified\n",
    "            lang_goal = self.zero_input(lang_goal) if self.args.zero_goal else lang_goal\n",
    "            lang_instr = self.zero_input(lang_instr) if self.args.zero_instr else lang_instr\n",
    "            \n",
    "            # append goal\n",
    "            feat['lang_goal'].append(lang_goal)\n",
    "            \n",
    "            # append instr\n",
    "            feat['lang_instr'].append(lang_instr)\n",
    "            \n",
    "            # append goal + instr\n",
    "            lang_goal_instr = lang_goal + lang_instr\n",
    "            feat['lang_goal_instr'].append(lang_goal_instr)\n",
    "            \n",
    "            # Skipped loading Resnet features from disk\n",
    "            \n",
    "            #########\n",
    "            # inputs\n",
    "            #########\n",
    "            \n",
    "            if not self.test_mode:\n",
    "                # low-level action\n",
    "                feat['action_low'].append([a['action'] for a in ex['num']['action_low']])\n",
    "        \n",
    "        # TODO -- embed action in addition to language\n",
    "        # tensorization and padding                \n",
    "        for k, v in feat.items():\n",
    "            if k in {'lang_goal_instr', 'lang_goal', 'lang_instr'}:\n",
    "                # language embedding and padding\n",
    "                seqs = [torch.tensor(vv, device=device) for vv in v]\n",
    "                pad_seq = pad_sequence(seqs, batch_first=True, padding_value=self.pad)\n",
    "                seq_lengths = np.array(list(map(len, v)))\n",
    "                embed_seq = self.emb_word(pad_seq)\n",
    "                packed_input = pack_padded_sequence(embed_seq, seq_lengths, batch_first=True, enforce_sorted=False)\n",
    "                feat[k] = packed_input\n",
    "            else:\n",
    "                # default: tensorize and pad sequence\n",
    "                seqs = [torch.tensor(vv, device=device, dtype=torch.float if ('frames' in k) else torch.long) for vv in v]\n",
    "                pad_seq = pad_sequence(seqs, batch_first=True, padding_value=self.pad)\n",
    "                feat[k] = pad_seq             \n",
    "    \n",
    "        return feat\n",
    "    \n",
    "    def serialize_lang_action(self, feat):\n",
    "        '''\n",
    "        append segmented instr language and low-level actions into single sequences\n",
    "        '''\n",
    "        is_serialized = not isinstance(feat['num']['lang_instr'][0], list)\n",
    "        if not is_serialized:\n",
    "            feat['num']['lang_instr'] = [word for desc in feat['num']['lang_instr'] for word in desc]\n",
    "            if not self.test_mode:\n",
    "                feat['num']['action_low'] = [a for a_group in feat['num']['action_low'] for a in a_group]\n",
    "\n",
    "    def forward(self, feat, max_decode=300):\n",
    "        cont_act, enc_act = self.encode_act(feat)\n",
    "        state_0 = cont_act, torch.zeros.like(cont_act)\n",
    "        res = self.dec(enc_act, max_decode=300, gold=feat['???'], state_0=state_0)\n",
    "        feat.update(res)\n",
    "        return feat\n",
    "    \n",
    "    def encode_act(self, feat):\n",
    "        '''\n",
    "        encode low-level actions\n",
    "        '''    \n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        pass\n",
    "    \n",
    "    def step(self, feat, prev_action=None):\n",
    "        '''\n",
    "        forward the model for a single time-step (used for real-time execution during eval)\n",
    "        '''\n",
    "        # DO WE NEED THIS?\n",
    "        pass\n",
    "    \n",
    "    def extract_preds(self, out, batch, feat, clean_special_tokens=True):\n",
    "        # MAY NOT NEED THIS\n",
    "        return preds\n",
    "\n",
    "    def embed_action(self, action):\n",
    "        '''\n",
    "        embed low-level action\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "#     def weighted_mask_loss(self, pred_masks, gt_masks):\n",
    "#     def flip_tensor(self, tensor, on_zero=1, on_non_zero=0):\n",
    "    \n",
    "    def compute_loss(self, out, batch, feat):\n",
    "        pass\n",
    "    \n",
    "    def compute_metric(self, preds, data):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

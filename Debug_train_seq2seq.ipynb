{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training cycle debugging\n",
    "\n",
    "Basically run code copied from train_seq2seq.py in this notebook to catch bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['ALFRED_ROOT'] = '/root/data/home/hoyeung/alfred/'\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.environ['ALFRED_ROOT']))\n",
    "sys.path.append(os.path.join(os.environ['ALFRED_ROOT'], 'models'))\n",
    "\n",
    "# from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser\n",
    "import torch\n",
    "import pprint\n",
    "import json\n",
    "from data.preprocess import Dataset\n",
    "from importlib import import_module, reload\n",
    "from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser\n",
    "from models.utils.helper_utils import optimizer_to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the default flags present in train_seq2seq.py\n",
    "\n",
    "parser = ArgumentParser(formatter_class=ArgumentDefaultsHelpFormatter)\n",
    "args = parser.parse_args('')\n",
    "\n",
    "# settings\n",
    "args.seed = 123\n",
    "args.data = '/root/data_alfred/json_feat_2.1.0'\n",
    "args.splits = '/root/data_alfred/splits/may17.json'\n",
    "args.object_vocab = 'objects_20200522'\n",
    "args.preprocess = False #!\n",
    "args.pp_folder = 'pp'\n",
    "args.monitor_train_every = 10\n",
    "args.save_every_epoch = False #!\n",
    "args.model = 'seq2seq_per_subgoal'\n",
    "args.gpu = True\n",
    "args.dout = 'exp/model:seq2seq_per_subgoal'\n",
    "args.resume = False #!\n",
    "\n",
    "# hyper parameters\n",
    "args.batch = 8\n",
    "args.epoch = 20\n",
    "args.lr = 1e-4\n",
    "args.decay_epoch = 10\n",
    "args.dhid = 512\n",
    "args.dframe = 2500\n",
    "args.demb = 100\n",
    "args.pframe = 300\n",
    "args.mask_loss_wt = 1.\n",
    "args.action_loss_wt = 1.\n",
    "args.subgoal_aux_loss_wt = 0.\n",
    "args.pm_aux_loss_wt = 0.\n",
    "\n",
    "# architecture ablations\n",
    "# args.maxpool_over_object_states = False\n",
    "# args.aux_loss_over_object_states = False\n",
    "args.encoder_addons = 'none'\n",
    "args.decoder_addons = 'none'\n",
    "args.object_repr = 'type'\n",
    "\n",
    "# dropouts\n",
    "args.zero_goal = False #!\n",
    "args.zero_instr = False #!\n",
    "args.act_dropout = 0.\n",
    "args.lang_dropout = 0.\n",
    "args.input_dropout = 0.\n",
    "args.vis_dropout = 0.3\n",
    "args.hstate_dropout = 0.3\n",
    "args.attn_dropout = 0.\n",
    "args.actor_dropout = 0.\n",
    "args.word_dropout = 0.\n",
    "\n",
    "# other settings\n",
    "args.train_teacher_forcing = False #!\n",
    "args.train_student_forcing_prob = 0.1\n",
    "args.temp_no_history = False #!\n",
    "\n",
    "# debugging\n",
    "args.fast_epoch = False #!\n",
    "args.dataset_fraction = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite the default flags\n",
    "\n",
    "args.preprocess = False # Turn this to True if running for the first time\n",
    "\n",
    "args.model = 'seq2seq_per_subgoal'  # found under models/model/ directory\n",
    "args.dout = '/root/data_alfred/exp/model:seq2seq_per_subgoal_biattn_instance_fast_epoch'\n",
    "\n",
    "args.train_teacher_forcing = True\n",
    "args.gpu = False\n",
    "\n",
    "# light setup for debugging\n",
    "args.fast_epoch = True # Turn this to False if running for the first time to preprocess data properly\n",
    "args.epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.maxpool_over_object_states = True\n",
    "# args.aux_loss_over_object_states = True\n",
    "\n",
    "args.encoder_addons = 'biattn_obj'\n",
    "args.decoder_addons = 'aux_loss'\n",
    "args.object_repr = 'instance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7efeb80a6810>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and load data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.out  /root/data_alfred/exp/model:seq2seq_per_subgoal_biattn_instance_fast_epoch\n"
     ]
    }
   ],
   "source": [
    "# make output dir\n",
    "if not os.path.isdir(args.dout):\n",
    "    os.makedirs(args.dout)\n",
    "\n",
    "print('args.out ', args.dout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tests_seen': 1533,\n",
      " 'tests_unseen': 1529,\n",
      " 'train': 20806,\n",
      " 'train_sanity': 246,\n",
      " 'train_sanity_v1': 246,\n",
      " 'valid_seen': 814,\n",
      " 'valid_seen_v1': 249,\n",
      " 'valid_unseen': 818,\n",
      " 'valid_unseen_v1': 254}\n"
     ]
    }
   ],
   "source": [
    "# load train/valid/tests splits\n",
    "with open(args.splits) as f:\n",
    "    splits = json.load(f)\n",
    "    pprint.pprint({k: len(v) for k, v in splits.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action_high': Vocab(93), 'word': Vocab(2360), 'action_low': Vocab(15)}\n"
     ]
    }
   ],
   "source": [
    "# preprocess and save -- only need to preprocess once\n",
    "if args.preprocess:\n",
    "    print(\"\\nPreprocessing dataset and saving to %s folders ... This will take a while. Do this once as required.\" % args.pp_folder)\n",
    "    dataset = Dataset(args, None)\n",
    "    dataset.preprocess_splits(splits)\n",
    "    vocab = torch.load(os.path.join(args.dout, \"%s.vocab\" % args.pp_folder))\n",
    "else:\n",
    "    vocab = torch.load(os.path.join(args.data, \"%s.vocab\" % args.pp_folder))\n",
    "    \n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_vocab = torch.load(os.path.join(args.data, '%s.vocab' % args.object_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model architecture\n",
    "args.gpu = False\n",
    "args.resume = None # os.path.join(args.dout, 'best_seen.pth')\n",
    "\n",
    "M = import_module('model.{}'.format(args.model))\n",
    "if args.resume:\n",
    "    print(\"Loading: \" + args.resume)\n",
    "    model, optimizer, start_epoch = M.Module.load(args.resume)\n",
    "    print(\"Restarting at epoch {}/{}\".format(start_epoch, args.epoch-1))\n",
    "    if start_epoch >= args.epoch:\n",
    "        print('Checkpoint already finished {}/{} epochs.'.format(start_epoch, args.epoch))\n",
    "        sys.exit(0)\n",
    "else:\n",
    "    model = M.Module(args, vocab, object_vocab)\n",
    "    optimizer = None\n",
    "    start_epoch = 0\n",
    "\n",
    "if args.gpu:\n",
    "    model = model.to(torch.device('cuda'))\n",
    "    if not optimizer is None:\n",
    "        optimizer_to(optimizer, torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Module(\n",
       "  (emb_word): Embedding(2360, 100)\n",
       "  (emb_action_low): Embedding(15, 100)\n",
       "  (emb_object): Embedding(111, 100, padding_idx=0)\n",
       "  (instance_fc): Linear(in_features=201, out_features=512, bias=True)\n",
       "  (enc): ActionFrameAttnEncoderPerSubgoalObjAttn(\n",
       "    (emb): Embedding(15, 100)\n",
       "    (vis_dropout): Dropout(p=0.3, inplace=False)\n",
       "    (act_dropout): Dropout(p=0.0, inplace=True)\n",
       "    (vis_encoder): ResnetVisualEncoder(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (fc): Linear(in_features=3136, out_features=2500, bias=True)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (enc_att): SelfAttn(\n",
       "      (scorer): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    )\n",
       "    (encoder): LSTM(2600, 512, batch_first=True, bidirectional=True)\n",
       "    (input_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (hstate_dropout): Dropout(p=0.3, inplace=False)\n",
       "    (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (obj_emb): Embedding(111, 100, padding_idx=0)\n",
       "    (instance_fc): Linear(in_features=201, out_features=512, bias=True)\n",
       "    (obj_attn): DotAttn()\n",
       "    (h_tm1_fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (forward_cell): LSTMCell(3624, 512)\n",
       "    (backward_cell): LSTMCell(3624, 512)\n",
       "  )\n",
       "  (dec): LanguageDecoder(\n",
       "    (emb): Embedding(2360, 100)\n",
       "    (obj_emb): Embedding(111, 100, padding_idx=0)\n",
       "    (cell): LSTMCell(1124, 1024)\n",
       "    (attn): DotAttn()\n",
       "    (input_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (hstate_dropout): Dropout(p=0.3, inplace=False)\n",
       "    (word_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (word): Linear(in_features=2148, out_features=100, bias=True)\n",
       "    (h_tm1_fc): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (h_enc_fc): Linear(in_features=1, out_features=2, bias=True)\n",
       "    (instance_fc): Linear(in_features=201, out_features=512, bias=True)\n",
       "  )\n",
       "  (vis_dropout): Dropout(p=0.3, inplace=False)\n",
       "  (act_dropout): Dropout(p=0.0, inplace=True)\n",
       "  (aux_criterion): BCEWithLogitsLoss()\n",
       "  (language_crtierion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine model layers\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to: /root/data_alfred/exp/model:seq2seq_per_subgoal_biattn_instance_fast_epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/data/home/hoyeung/alfred/models/model/seq2seq_per_subgoal.py:296: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  empty_tensor = torch.ones(torch.tensor(v[0][0][0]).unsqueeze(0).shape, device=device, dtype=torch.float if ('frames' in k) else torch.long) * self.pad\n",
      "/root/data/home/hoyeung/alfred/models/model/seq2seq_per_subgoal.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  seqs.append(torch.tensor(v[subgoal_i][batch_i], device=device, dtype=torch.float if ('frames' in k) else torch.long))\n",
      "/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/functional.py:1350: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "\n",
      "batch:  50%|█████     | 1/2 [00:17<00:17, 17.85s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:37<00:00, 18.91s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:03<00:03,  3.10s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:06<00:00,  3.12s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:04<00:04,  4.70s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:09<00:00,  4.94s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:07<00:07,  7.86s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:14<00:00,  7.03s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:21<00:21, 21.16s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:32<00:00, 16.29s/it]\u001b[A\n",
      "/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:30<00:30, 30.23s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:56<00:00, 28.49s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:28<00:28, 28.53s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:51<00:00, 25.70s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found new best valid_seen!! Saving...\n",
      "Found new best valid_unseen!! Saving...\n",
      "Found new best train_sanity!! Saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  20%|██        | 1/5 [03:33<14:14, 213.74s/it]\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0,\n",
      " 'train_sanity': {'BLEU': 2.1643244568036305e-232,\n",
      "                  'perplexity': 256.3981170654297,\n",
      "                  'total_loss': 314.7671890258789},\n",
      " 'valid_seen': {'BLEU': 2.3009385374372878e-232,\n",
      "                'perplexity': 272.8842468261719,\n",
      "                'total_loss': 669.7962036132812},\n",
      " 'valid_unseen': {'BLEU': 2.33772413597026e-232,\n",
      "                  'perplexity': 273.24156188964844,\n",
      "                  'total_loss': 183.23194122314453}}\n",
      "epoch_time                    213.74                                  \n",
      "compute_metrics_validation_sets174.366                                 \n",
      "forward_batch_train_with_iterate37.815                                  \n",
      "forward_batch_train           37.342                                  \n",
      "iterate_featurize             0.563                                   \n",
      "featurize_tensorization_and_padding0.371                                   \n",
      "torch_save_train_sanity       0.357                                   \n",
      "torch_save_valid_unseen       0.343                                   \n",
      "torch_save_valid_seen         0.337                                   \n",
      "torch_save_last               0.336                                   \n",
      "iterate_load_task_json        0.19                                    \n",
      "featurize_input_resnet_features0.129                                   \n",
      "make_debug_valid_unseen       0.099                                   \n",
      "featurize_torch_load_time     0.074                                   \n",
      "make_debug_valid_seen         0.042                                   \n",
      "make_debug_train              0.042                                   \n",
      "setup_time                    0.001                                   \n",
      "featurize_input_action_low    0.0                                     \n",
      "compute_metrics_train         0.0                                     \n",
      "featurize_outputs             0.0                                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "batch:  50%|█████     | 1/2 [00:16<00:16, 16.82s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:37<00:00, 18.72s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:04<00:04,  4.51s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:06<00:00,  3.47s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:04<00:04,  4.63s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:08<00:00,  4.24s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:03<00:03,  3.91s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:07<00:00,  3.93s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:30<00:30, 30.50s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:41<00:00, 20.88s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:26<00:26, 26.63s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:54<00:00, 27.37s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:24<00:24, 24.51s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:51<00:00, 25.70s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found new best valid_seen!! Saving...\n",
      "Found new best valid_unseen!! Saving...\n",
      "Found new best train_sanity!! Saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  40%|████      | 2/5 [07:21<10:54, 218.03s/it]\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1,\n",
      " 'train_sanity': {'BLEU': 2.95389062398692e-232,\n",
      "                  'perplexity': 147.60362243652344,\n",
      "                  'total_loss': 441.4262442588806},\n",
      " 'valid_seen': {'BLEU': 1.0539061720264464e-157,\n",
      "                'perplexity': 159.03913116455078,\n",
      "                'total_loss': 1076.8172297477722},\n",
      " 'valid_unseen': {'BLEU': 2.827275255539971e-232,\n",
      "                  'perplexity': 153.6688461303711,\n",
      "                  'total_loss': 9.376019954681396}}\n",
      "epoch_time                    441.79                                  \n",
      "compute_metrics_validation_sets346.948                                 \n",
      "forward_batch_train_with_iterate75.267                                  \n",
      "forward_batch_train           74.339                                  \n",
      "torch_save_last               5.226                                   \n",
      "torch_save_valid_seen         5.126                                   \n",
      "torch_save_valid_unseen       4.399                                   \n",
      "torch_save_train_sanity       4.386                                   \n",
      "iterate_featurize             1.074                                   \n",
      "featurize_tensorization_and_padding0.705                                   \n",
      "iterate_load_task_json        0.388                                   \n",
      "featurize_input_resnet_features0.228                                   \n",
      "make_debug_valid_unseen       0.201                                   \n",
      "make_debug_train              0.139                                   \n",
      "featurize_torch_load_time     0.132                                   \n",
      "make_debug_valid_seen         0.089                                   \n",
      "compute_metrics_train         0.003                                   \n",
      "setup_time                    0.001                                   \n",
      "featurize_input_action_low    0.001                                   \n",
      "featurize_outputs             0.0                                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "batch:  50%|█████     | 1/2 [00:17<00:17, 17.96s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:32<00:00, 16.16s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:05<00:05,  5.79s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:08<00:00,  4.23s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:05<00:05,  5.85s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:10<00:00,  5.48s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:04<00:04,  4.57s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:07<00:00,  3.93s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:22<00:22, 22.52s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:36<00:00, 18.14s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:30<00:30, 30.29s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [01:02<00:00, 31.30s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:28<00:28, 28.30s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:59<00:00, 29.86s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found new best valid_seen!! Saving...\n",
      "Found new best valid_unseen!! Saving...\n",
      "Found new best train_sanity!! Saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  40%|████      | 2/5 [11:13<16:49, 336.64s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2a79b170a1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# main training loop -- debug here if breakpoints were inserted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/data/home/hoyeung/alfred/models/model/seq2seq.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(self, splits, args, optimizer, start_epoch)\u001b[0m\n\u001b[1;32m    290\u001b[0m                     \u001b[0;34m'object_vocab'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_vocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                     \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m                 }, fsave)\n\u001b[0m\u001b[1;32m    293\u001b[0m                 \u001b[0mfbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'best_train_sanity.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfbest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \"\"\"\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# main training loop -- debug here if breakpoints were inserted\n",
    "model.run_train(splits, optimizer=optimizer, start_epoch=start_epoch)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# old branch per-subgoal BASELINE\n",
    "\n",
    "{'epoch': 0,\n",
    " 'train_sanity': {'BLEU': 2.638813586708307e-232,\n",
    "                  'perplexity': 175.3822250366211,\n",
    "                  'total_loss': 7.454048156738281},\n",
    " 'valid_seen': {'BLEU': 2.7649164470978882e-232,\n",
    "                'perplexity': 180.12401580810547,\n",
    "                'total_loss': 7.491679668426514},\n",
    " 'valid_unseen': {'BLEU': 2.3879481169065848e-232,\n",
    "                  'perplexity': 160.17532348632812,\n",
    "                  'total_loss': 7.323445796966553}}\n",
    "epoch_time                    118.513                                 \n",
    "compute_metrics_validation_sets105.05                                  \n",
    "forward_batch_train_with_iterate12.287                                  \n",
    "forward_batch_train           11.946                                  \n",
    "iterate_featurize             0.326                                   \n",
    "torch_save_valid_seen         0.261                                   \n",
    "torch_save_last               0.252                                   \n",
    "torch_save_valid_unseen       0.247                                   \n",
    "torch_save_train_sanity       0.24                                    \n",
    "iterate_load_task_json        0.175                                   \n",
    "featurize_tensorization_and_padding0.158                                   \n",
    "featurize_input_resnet_features0.143                                   \n",
    "make_debug_valid_unseen       0.091                                   \n",
    "featurize_torch_load_time     0.09                                    \n",
    "make_debug_valid_seen         0.041                                   \n",
    "make_debug_train              0.041                                   \n",
    "setup_time                    0.001                                   \n",
    "featurize_input_action_low    0.0                                     \n",
    "compute_metrics_train         0.0                                     \n",
    "featurize_outputs             0.0 "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "{'epoch': 0,\n",
    " 'train_sanity': {'BLEU': 1.8747843191033304e-232,\n",
    "                  'perplexity': 176.1246566772461,\n",
    "                  'total_loss': 7.460198402404785},\n",
    " 'valid_seen': {'BLEU': 2.5034942568793152e-232,\n",
    "                'perplexity': 180.14256286621094,\n",
    "                'total_loss': 7.49180793762207},\n",
    " 'valid_unseen': {'BLEU': 2.1108175036585326e-232,\n",
    "                  'perplexity': 160.90531158447266,\n",
    "                  'total_loss': 7.330006122589111}}\n",
    "epoch_time                    229.403                                 \n",
    "compute_metrics_validation_sets193.46                                  \n",
    "forward_batch_train_with_iterate34.642                                  \n",
    "forward_batch_train           34.261                                  \n",
    "iterate_featurize             0.324                                   \n",
    "torch_save_valid_seen         0.274                                   \n",
    "torch_save_train_sanity       0.267                                   \n",
    "torch_save_last               0.263                                   \n",
    "torch_save_valid_unseen       0.262                                   \n",
    "iterate_load_task_json        0.216                                   \n",
    "featurize_input_resnet_features0.165                                   \n",
    "featurize_tensorization_and_padding0.158                                   \n",
    "make_debug_valid_seen         0.097                                   \n",
    "make_debug_train              0.092                                   \n",
    "featurize_torch_load_time     0.088                                   \n",
    "make_debug_valid_unseen       0.043                                   \n",
    "setup_time                    0.001                                   \n",
    "featurize_input_action_low    0.001                                   \n",
    "compute_metrics_train         0.0                                     \n",
    "featurize_outputs             0.0 "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# old branch BI-ATTN + AUX LOSS\n",
    "\n",
    "{'epoch': 0,\n",
    " 'train_sanity': {'BLEU': 5.272791609271694e-157,\n",
    "                  'perplexity': 133.40389251708984,\n",
    "                  'total_loss': 15.418501377105713},\n",
    " 'valid_seen': {'BLEU': 1.2697489715465426e-157,\n",
    "                'perplexity': 135.36600494384766,\n",
    "                'total_loss': 15.778061866760254},\n",
    " 'valid_unseen': {'BLEU': 1.3425960742964622e-157,\n",
    "                  'perplexity': 127.78440856933594,\n",
    "                  'total_loss': 15.614015579223633}}\n",
    "epoch_time                    237.858                                 \n",
    "compute_metrics_validation_sets204.668                                 \n",
    "forward_batch_train_with_iterate31.603                                  \n",
    "forward_batch_train           31.278                                  \n",
    "torch_save_train_sanity       0.344                                   \n",
    "iterate_featurize             0.34                                    \n",
    "torch_save_last               0.339                                   \n",
    "torch_save_valid_unseen       0.336                                   \n",
    "torch_save_valid_seen         0.327                                   \n",
    "featurize_tensorization_and_padding0.183                                   \n",
    "iterate_load_task_json        0.167                                   \n",
    "featurize_input_resnet_features0.134                                   \n",
    "make_debug_valid_unseen       0.101                                   \n",
    "make_debug_valid_seen         0.097                                   \n",
    "featurize_torch_load_time     0.076                                   \n",
    "make_debug_train              0.041                                   \n",
    "setup_time                    0.001                                   \n",
    "featurize_input_action_low    0.0                                     \n",
    "featurize_outputs             0.0                                     \n",
    "compute_metrics_train         0.0  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BI-ATTN + AUX LOSS\n",
    "\n",
    "{'epoch': 0,\n",
    " 'train_sanity': {'BLEU': 5.272791609271694e-157,\n",
    "                  'perplexity': 133.4038314819336,\n",
    "                  'total_loss': 15.418500900268555},\n",
    " 'valid_seen': {'BLEU': 1.2697489715465426e-157,\n",
    "                'perplexity': 135.36604690551758,\n",
    "                'total_loss': 15.778063297271729},\n",
    " 'valid_unseen': {'BLEU': 1.3425960742964622e-157,\n",
    "                  'perplexity': 127.78447341918945,\n",
    "                  'total_loss': 15.614017486572266}}\n",
    "epoch_time                    255.655                                 \n",
    "compute_metrics_validation_sets219.629                                 \n",
    "forward_batch_train_with_iterate34.462                                  \n",
    "forward_batch_train           34.142                                  \n",
    "torch_save_train_sanity       0.33                                    \n",
    "torch_save_valid_unseen       0.326                                   \n",
    "torch_save_last               0.326                                   \n",
    "torch_save_valid_seen         0.324                                   \n",
    "iterate_featurize             0.318                                   \n",
    "iterate_load_task_json        0.172                                   \n",
    "featurize_tensorization_and_padding0.162                                   \n",
    "featurize_input_resnet_features0.131                                   \n",
    "make_debug_valid_seen         0.105                                   \n",
    "make_debug_valid_unseen       0.093                                   \n",
    "featurize_torch_load_time     0.075                                   \n",
    "make_debug_train              0.053                                   \n",
    "setup_time                    0.001                                   \n",
    "compute_metrics_train         0.001                                   \n",
    "featurize_input_action_low    0.0                                     \n",
    "featurize_outputs             0.0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BI-ATTN + AUX LOSS\n",
    "# INSTANCE BASED\n",
    "\n",
    "{'epoch': 0,\n",
    " 'train_sanity': {'BLEU': 2.1643244568036305e-232,\n",
    "                  'perplexity': 256.3981170654297,\n",
    "                  'total_loss': 314.7671890258789},\n",
    " 'valid_seen': {'BLEU': 2.3009385374372878e-232,\n",
    "                'perplexity': 272.8842468261719,\n",
    "                'total_loss': 669.7962036132812},\n",
    " 'valid_unseen': {'BLEU': 2.33772413597026e-232,\n",
    "                  'perplexity': 273.24156188964844,\n",
    "                  'total_loss': 183.23194122314453}}\n",
    "epoch_time                    213.74                                  \n",
    "compute_metrics_validation_sets174.366                                 \n",
    "forward_batch_train_with_iterate37.815                                  \n",
    "forward_batch_train           37.342                                  \n",
    "iterate_featurize             0.563                                   \n",
    "featurize_tensorization_and_padding0.371                                   \n",
    "torch_save_train_sanity       0.357                                   \n",
    "torch_save_valid_unseen       0.343                                   \n",
    "torch_save_valid_seen         0.337                                   \n",
    "torch_save_last               0.336                                   \n",
    "iterate_load_task_json        0.19                                    \n",
    "featurize_input_resnet_features0.129                                   \n",
    "make_debug_valid_unseen       0.099                                   \n",
    "featurize_torch_load_time     0.074                                   \n",
    "make_debug_valid_seen         0.042                                   \n",
    "make_debug_train              0.042                                   \n",
    "setup_time                    0.001                                   \n",
    "featurize_input_action_low    0.0                                     \n",
    "compute_metrics_train         0.0                                     \n",
    "featurize_outputs             0.0 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

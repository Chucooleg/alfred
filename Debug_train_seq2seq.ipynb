{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training cycle debugging\n",
    "\n",
    "Basically run code copied from train_seq2seq.py in this notebook to catch bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['ALFRED_ROOT'] = '/root/data/home/hoyeung/alfred/'\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.environ['ALFRED_ROOT']))\n",
    "sys.path.append(os.path.join(os.environ['ALFRED_ROOT'], 'models'))\n",
    "\n",
    "# from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser\n",
    "import torch\n",
    "import pprint\n",
    "import json\n",
    "from data.preprocess import Dataset\n",
    "from importlib import import_module, reload\n",
    "from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser\n",
    "from models.utils.helper_utils import optimizer_to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the default flags present in train_seq2seq.py\n",
    "\n",
    "parser = ArgumentParser(formatter_class=ArgumentDefaultsHelpFormatter)\n",
    "args = parser.parse_args('')\n",
    "\n",
    "# settings\n",
    "args.seed = 123\n",
    "args.data = '/root/data_alfred/json_feat_2.1.0'\n",
    "args.splits = '/root/data_alfred/splits/may17.json'\n",
    "args.object_vocab = 'objects_20200522'\n",
    "args.preprocess = False #!\n",
    "args.pp_folder = 'pp'\n",
    "args.monitor_train_every = 10\n",
    "args.save_every_epoch = False #!\n",
    "args.model = 'seq2seq_per_subgoal'\n",
    "args.gpu = True\n",
    "args.dout = 'exp/model:seq2seq_per_subgoal'\n",
    "args.resume = False #!\n",
    "\n",
    "# hyper parameters\n",
    "args.batch = 8\n",
    "args.epoch = 20\n",
    "args.lr = 1e-4\n",
    "args.decay_epoch = 10\n",
    "args.dhid = 512\n",
    "args.dframe = 2500\n",
    "args.demb = 100\n",
    "args.pframe = 300\n",
    "args.mask_loss_wt = 1.\n",
    "args.action_loss_wt = 1.\n",
    "args.subgoal_aux_loss_wt = 0.\n",
    "args.pm_aux_loss_wt = 0.\n",
    "\n",
    "# architecture ablations\n",
    "# args.maxpool_over_object_states = False\n",
    "# args.aux_loss_over_object_states = False\n",
    "args.encoder_addons = 'none'\n",
    "args.decoder_addons = 'none'\n",
    "args.object_repr = 'type'\n",
    "\n",
    "# dropouts\n",
    "args.zero_goal = False #!\n",
    "args.zero_instr = False #!\n",
    "args.act_dropout = 0.\n",
    "args.lang_dropout = 0.\n",
    "args.input_dropout = 0.\n",
    "args.vis_dropout = 0.3\n",
    "args.hstate_dropout = 0.3\n",
    "args.attn_dropout = 0.\n",
    "args.actor_dropout = 0.\n",
    "args.word_dropout = 0.\n",
    "\n",
    "# other settings\n",
    "args.train_teacher_forcing = False #!\n",
    "args.train_student_forcing_prob = 0.1\n",
    "args.temp_no_history = False #!\n",
    "\n",
    "# debugging\n",
    "args.fast_epoch = False #!\n",
    "args.dataset_fraction = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite the default flags\n",
    "\n",
    "args.preprocess = False # Turn this to True if running for the first time\n",
    "\n",
    "args.model = 'seq2seq_per_subgoal'  # found under models/model/ directory\n",
    "args.dout = '/root/data_alfred/exp/model:seq2seq_per_subgoal_biattn_fast_epoch'\n",
    "\n",
    "args.train_teacher_forcing = True\n",
    "args.gpu = False\n",
    "\n",
    "# light setup for debugging\n",
    "args.fast_epoch = True # Turn this to False if running for the first time to preprocess data properly\n",
    "args.epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.maxpool_over_object_states = True\n",
    "# args.aux_loss_over_object_states = True\n",
    "\n",
    "args.encoder_addons = 'biattn_obj'\n",
    "args.decoder_addons = 'aux_loss'\n",
    "args.object_repr = 'instance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff8e81895b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and load data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.out  /root/data_alfred/exp/model:seq2seq_per_subgoal_biattn_fast_epoch\n"
     ]
    }
   ],
   "source": [
    "# make output dir\n",
    "if not os.path.isdir(args.dout):\n",
    "    os.makedirs(args.dout)\n",
    "\n",
    "print('args.out ', args.dout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tests_seen': 1533,\n",
      " 'tests_unseen': 1529,\n",
      " 'train': 20806,\n",
      " 'train_sanity': 246,\n",
      " 'train_sanity_v1': 246,\n",
      " 'valid_seen': 814,\n",
      " 'valid_seen_v1': 249,\n",
      " 'valid_unseen': 818,\n",
      " 'valid_unseen_v1': 254}\n"
     ]
    }
   ],
   "source": [
    "# load train/valid/tests splits\n",
    "with open(args.splits) as f:\n",
    "    splits = json.load(f)\n",
    "    pprint.pprint({k: len(v) for k, v in splits.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action_high': Vocab(93), 'word': Vocab(2360), 'action_low': Vocab(15)}\n"
     ]
    }
   ],
   "source": [
    "# preprocess and save -- only need to preprocess once\n",
    "if args.preprocess:\n",
    "    print(\"\\nPreprocessing dataset and saving to %s folders ... This will take a while. Do this once as required.\" % args.pp_folder)\n",
    "    dataset = Dataset(args, None)\n",
    "    dataset.preprocess_splits(splits)\n",
    "    vocab = torch.load(os.path.join(args.dout, \"%s.vocab\" % args.pp_folder))\n",
    "else:\n",
    "    vocab = torch.load(os.path.join(args.data, \"%s.vocab\" % args.pp_folder))\n",
    "    \n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_vocab = torch.load(os.path.join(args.data, '%s.vocab' % args.object_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model architecture\n",
    "args.gpu = False\n",
    "args.resume = None # os.path.join(args.dout, 'best_seen.pth')\n",
    "\n",
    "M = import_module('model.{}'.format(args.model))\n",
    "if args.resume:\n",
    "    print(\"Loading: \" + args.resume)\n",
    "    model, optimizer, start_epoch = M.Module.load(args.resume)\n",
    "    print(\"Restarting at epoch {}/{}\".format(start_epoch, args.epoch-1))\n",
    "    if start_epoch >= args.epoch:\n",
    "        print('Checkpoint already finished {}/{} epochs.'.format(start_epoch, args.epoch))\n",
    "        sys.exit(0)\n",
    "else:\n",
    "    model = M.Module(args, vocab, object_vocab)\n",
    "    optimizer = None\n",
    "    start_epoch = 0\n",
    "\n",
    "if args.gpu:\n",
    "    model = model.to(torch.device('cuda'))\n",
    "    if not optimizer is None:\n",
    "        optimizer_to(optimizer, torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Module(\n",
       "  (emb_word): Embedding(2360, 100)\n",
       "  (emb_action_low): Embedding(15, 100)\n",
       "  (emb_object): Embedding(111, 100, padding_idx=0)\n",
       "  (instance_fc): Linear(in_features=201, out_features=512, bias=True)\n",
       "  (enc): ActionFrameAttnEncoderPerSubgoalObjAttn(\n",
       "    (emb): Embedding(15, 100)\n",
       "    (vis_dropout): Dropout(p=0.3, inplace=False)\n",
       "    (act_dropout): Dropout(p=0.0, inplace=True)\n",
       "    (vis_encoder): ResnetVisualEncoder(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (fc): Linear(in_features=3136, out_features=2500, bias=True)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (enc_att): SelfAttn(\n",
       "      (scorer): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    )\n",
       "    (encoder): LSTM(2600, 512, batch_first=True, bidirectional=True)\n",
       "    (input_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (hstate_dropout): Dropout(p=0.3, inplace=False)\n",
       "    (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (obj_emb): Embedding(111, 100, padding_idx=0)\n",
       "    (instance_fc): Linear(in_features=201, out_features=512, bias=True)\n",
       "    (obj_attn): DotAttn()\n",
       "    (h_tm1_fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (forward_cell): LSTMCell(3624, 512)\n",
       "    (backward_cell): LSTMCell(3624, 512)\n",
       "  )\n",
       "  (dec): LanguageDecoder(\n",
       "    (emb): Embedding(2360, 100)\n",
       "    (obj_emb): Embedding(111, 100, padding_idx=0)\n",
       "    (cell): LSTMCell(1124, 1024)\n",
       "    (attn): DotAttn()\n",
       "    (input_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (hstate_dropout): Dropout(p=0.3, inplace=False)\n",
       "    (word_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (word): Linear(in_features=2148, out_features=100, bias=True)\n",
       "    (h_tm1_fc): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (h_enc_fc): Linear(in_features=1, out_features=2, bias=True)\n",
       "    (instance_fc): Linear(in_features=201, out_features=512, bias=True)\n",
       "  )\n",
       "  (vis_dropout): Dropout(p=0.3, inplace=False)\n",
       "  (act_dropout): Dropout(p=0.0, inplace=True)\n",
       "  (aux_criterion): BCEWithLogitsLoss()\n",
       "  (language_crtierion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine model layers\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to: /root/data_alfred/exp/model:seq2seq_per_subgoal_biattn_fast_epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'instance_receptacle_change'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2a79b170a1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# main training loop -- debug here if breakpoints were inserted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/data/home/hoyeung/alfred/models/model/seq2seq.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(self, splits, args, optimizer, start_epoch)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;31m# time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mepoch_loop_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterate_time_report\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m                 \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/home/hoyeung/alfred/models/model/seq2seq.py\u001b[0m in \u001b[0;36miterate\u001b[0;34m(self, data, batch_size)\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;31m# time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m             \u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeaturize_time_report\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeaturize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m             \u001b[0;31m# time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0mtime_report\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iterate_featurize'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/home/hoyeung/alfred/models/model/seq2seq_per_subgoal.py\u001b[0m in \u001b[0;36mfeaturize\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    245\u001b[0m                         \u001b[0mfeat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'object_state_change_since_last_subgoal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubgoal_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_i\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'instance_state_change_since_last_subgoal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubgoal_i\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_objects\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# include <<stop>>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                         \u001b[0mfeat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'object_visibility'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubgoal_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_i\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'instance_visibile'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubgoal_i\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mobj_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'instance_visibile'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubgoal_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# include <<stop>>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m                         \u001b[0mfeat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'object_receptacle_change'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubgoal_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_i\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'instance_receptacle_change'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubgoal_i\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_objects\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# include <<stop>>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m                         \u001b[0mfeat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'object_receptacle_change_since_last_subgoal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubgoal_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_i\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'instance_receptacle_change_since_last_subgoal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubgoal_i\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_objects\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# include <<stop>>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                         \u001b[0mfeat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'object_distance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubgoal_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_i\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'instance_distance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubgoal_i\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mobj_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'instance_distance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubgoal_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# include <<stop>>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'instance_receptacle_change'"
     ]
    }
   ],
   "source": [
    "# main training loop -- debug here if breakpoints were inserted\n",
    "model.run_train(splits, optimizer=optimizer, start_epoch=start_epoch)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# old branch per-subgoal BASELINE\n",
    "\n",
    "{'epoch': 0,\n",
    " 'train_sanity': {'BLEU': 2.638813586708307e-232,\n",
    "                  'perplexity': 175.3822250366211,\n",
    "                  'total_loss': 7.454048156738281},\n",
    " 'valid_seen': {'BLEU': 2.7649164470978882e-232,\n",
    "                'perplexity': 180.12401580810547,\n",
    "                'total_loss': 7.491679668426514},\n",
    " 'valid_unseen': {'BLEU': 2.3879481169065848e-232,\n",
    "                  'perplexity': 160.17532348632812,\n",
    "                  'total_loss': 7.323445796966553}}\n",
    "epoch_time                    118.513                                 \n",
    "compute_metrics_validation_sets105.05                                  \n",
    "forward_batch_train_with_iterate12.287                                  \n",
    "forward_batch_train           11.946                                  \n",
    "iterate_featurize             0.326                                   \n",
    "torch_save_valid_seen         0.261                                   \n",
    "torch_save_last               0.252                                   \n",
    "torch_save_valid_unseen       0.247                                   \n",
    "torch_save_train_sanity       0.24                                    \n",
    "iterate_load_task_json        0.175                                   \n",
    "featurize_tensorization_and_padding0.158                                   \n",
    "featurize_input_resnet_features0.143                                   \n",
    "make_debug_valid_unseen       0.091                                   \n",
    "featurize_torch_load_time     0.09                                    \n",
    "make_debug_valid_seen         0.041                                   \n",
    "make_debug_train              0.041                                   \n",
    "setup_time                    0.001                                   \n",
    "featurize_input_action_low    0.0                                     \n",
    "compute_metrics_train         0.0                                     \n",
    "featurize_outputs             0.0 "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "{'epoch': 0,\n",
    " 'train_sanity': {'BLEU': 1.8747843191033304e-232,\n",
    "                  'perplexity': 176.1246566772461,\n",
    "                  'total_loss': 7.460198402404785},\n",
    " 'valid_seen': {'BLEU': 2.5034942568793152e-232,\n",
    "                'perplexity': 180.14256286621094,\n",
    "                'total_loss': 7.49180793762207},\n",
    " 'valid_unseen': {'BLEU': 2.1108175036585326e-232,\n",
    "                  'perplexity': 160.90531158447266,\n",
    "                  'total_loss': 7.330006122589111}}\n",
    "epoch_time                    229.403                                 \n",
    "compute_metrics_validation_sets193.46                                  \n",
    "forward_batch_train_with_iterate34.642                                  \n",
    "forward_batch_train           34.261                                  \n",
    "iterate_featurize             0.324                                   \n",
    "torch_save_valid_seen         0.274                                   \n",
    "torch_save_train_sanity       0.267                                   \n",
    "torch_save_last               0.263                                   \n",
    "torch_save_valid_unseen       0.262                                   \n",
    "iterate_load_task_json        0.216                                   \n",
    "featurize_input_resnet_features0.165                                   \n",
    "featurize_tensorization_and_padding0.158                                   \n",
    "make_debug_valid_seen         0.097                                   \n",
    "make_debug_train              0.092                                   \n",
    "featurize_torch_load_time     0.088                                   \n",
    "make_debug_valid_unseen       0.043                                   \n",
    "setup_time                    0.001                                   \n",
    "featurize_input_action_low    0.001                                   \n",
    "compute_metrics_train         0.0                                     \n",
    "featurize_outputs             0.0 "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# old branch BI-ATTN + AUX LOSS\n",
    "\n",
    "{'epoch': 0,\n",
    " 'train_sanity': {'BLEU': 5.272791609271694e-157,\n",
    "                  'perplexity': 133.40389251708984,\n",
    "                  'total_loss': 15.418501377105713},\n",
    " 'valid_seen': {'BLEU': 1.2697489715465426e-157,\n",
    "                'perplexity': 135.36600494384766,\n",
    "                'total_loss': 15.778061866760254},\n",
    " 'valid_unseen': {'BLEU': 1.3425960742964622e-157,\n",
    "                  'perplexity': 127.78440856933594,\n",
    "                  'total_loss': 15.614015579223633}}\n",
    "epoch_time                    237.858                                 \n",
    "compute_metrics_validation_sets204.668                                 \n",
    "forward_batch_train_with_iterate31.603                                  \n",
    "forward_batch_train           31.278                                  \n",
    "torch_save_train_sanity       0.344                                   \n",
    "iterate_featurize             0.34                                    \n",
    "torch_save_last               0.339                                   \n",
    "torch_save_valid_unseen       0.336                                   \n",
    "torch_save_valid_seen         0.327                                   \n",
    "featurize_tensorization_and_padding0.183                                   \n",
    "iterate_load_task_json        0.167                                   \n",
    "featurize_input_resnet_features0.134                                   \n",
    "make_debug_valid_unseen       0.101                                   \n",
    "make_debug_valid_seen         0.097                                   \n",
    "featurize_torch_load_time     0.076                                   \n",
    "make_debug_train              0.041                                   \n",
    "setup_time                    0.001                                   \n",
    "featurize_input_action_low    0.0                                     \n",
    "featurize_outputs             0.0                                     \n",
    "compute_metrics_train         0.0  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# old branch BI-ATTN + AUX LOSS\n",
    "\n",
    "{'epoch': 0,\n",
    " 'train_sanity': {'BLEU': 5.272791609271694e-157,\n",
    "                  'perplexity': 133.4038314819336,\n",
    "                  'total_loss': 15.418500900268555},\n",
    " 'valid_seen': {'BLEU': 1.2697489715465426e-157,\n",
    "                'perplexity': 135.36604690551758,\n",
    "                'total_loss': 15.778063297271729},\n",
    " 'valid_unseen': {'BLEU': 1.3425960742964622e-157,\n",
    "                  'perplexity': 127.78447341918945,\n",
    "                  'total_loss': 15.614017486572266}}\n",
    "epoch_time                    255.655                                 \n",
    "compute_metrics_validation_sets219.629                                 \n",
    "forward_batch_train_with_iterate34.462                                  \n",
    "forward_batch_train           34.142                                  \n",
    "torch_save_train_sanity       0.33                                    \n",
    "torch_save_valid_unseen       0.326                                   \n",
    "torch_save_last               0.326                                   \n",
    "torch_save_valid_seen         0.324                                   \n",
    "iterate_featurize             0.318                                   \n",
    "iterate_load_task_json        0.172                                   \n",
    "featurize_tensorization_and_padding0.162                                   \n",
    "featurize_input_resnet_features0.131                                   \n",
    "make_debug_valid_seen         0.105                                   \n",
    "make_debug_valid_unseen       0.093                                   \n",
    "featurize_torch_load_time     0.075                                   \n",
    "make_debug_train              0.053                                   \n",
    "setup_time                    0.001                                   \n",
    "compute_metrics_train         0.001                                   \n",
    "featurize_input_action_low    0.0                                     \n",
    "featurize_outputs             0.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

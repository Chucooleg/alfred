{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training cycle debugging\n",
    "\n",
    "Basically run code copied from train_seq2seq.py in this notebook to catch bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['ALFRED_ROOT'] = '/root/data/home/hoyeung/alfred/'\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.environ['ALFRED_ROOT']))\n",
    "sys.path.append(os.path.join(os.environ['ALFRED_ROOT'], 'models'))\n",
    "\n",
    "# from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser\n",
    "import torch\n",
    "import pprint\n",
    "import json\n",
    "from data.preprocess import Dataset\n",
    "from importlib import import_module, reload\n",
    "from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser\n",
    "from models.utils.helper_utils import optimizer_to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the default flags present in train_seq2seq.py\n",
    "\n",
    "parser = ArgumentParser(formatter_class=ArgumentDefaultsHelpFormatter)\n",
    "args = parser.parse_args('')\n",
    "\n",
    "# settings\n",
    "args.seed = 123\n",
    "args.data = '/root/data_alfred/json_feat_2.1.0'\n",
    "args.splits = '/root/data_alfred/splits/apr25.json'\n",
    "args.preprocess = False #!\n",
    "args.pp_folder = 'pp'\n",
    "args.monitor_train_every = 10\n",
    "args.save_every_epoch = False #!\n",
    "args.model = 'seq2seq_per_subgoal'\n",
    "args.gpu = True\n",
    "args.dout = 'exp/model:seq2seq_per_subgoal'\n",
    "args.resume = False #!\n",
    "\n",
    "# hyper parameters\n",
    "args.batch = 8\n",
    "args.epoch = 20\n",
    "args.lr = 1e-4\n",
    "args.decay_epoch = 10\n",
    "args.dhid = 512\n",
    "args.dframe = 2500\n",
    "args.demb = 100\n",
    "args.pframe = 300\n",
    "args.mask_loss_wt = 1.\n",
    "args.action_loss_wt = 1.\n",
    "args.subgoal_aux_loss_wt = 0.\n",
    "args.pm_aux_loss_wt = 0.\n",
    "\n",
    "# dropouts\n",
    "args.zero_goal = False #!\n",
    "args.zero_instr = False #!\n",
    "args.act_dropout = 0.\n",
    "args.lang_dropout = 0.\n",
    "args.input_dropout = 0.\n",
    "args.vis_dropout = 0.3\n",
    "args.hstate_dropout = 0.3\n",
    "args.attn_dropout = 0.\n",
    "args.actor_dropout = 0.\n",
    "args.word_dropout = 0.\n",
    "\n",
    "# other settings\n",
    "args.train_teacher_forcing = False #!\n",
    "args.train_student_forcing_prob = 0.1\n",
    "args.temp_no_history = False #!\n",
    "\n",
    "# debugging\n",
    "args.fast_epoch = False #!\n",
    "args.dataset_fraction = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite the default flags\n",
    "\n",
    "args.preprocess = False # Turn this to True if running for the first time\n",
    "\n",
    "args.model = 'seq2seq_per_subgoal'  # found under models/model/ directory\n",
    "args.dout = '/root/data_alfred/exp/model:seq2seq_per_subgoal_fast_epoch'\n",
    "\n",
    "args.train_teacher_forcing = True\n",
    "args.gpu = False\n",
    "\n",
    "# light setup for debugging\n",
    "args.fast_epoch = True # Turn this to False if running for the first time to preprocess data properly\n",
    "args.epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fbc3e90c670>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and load data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.out  /root/data_alfred/exp/model:seq2seq_per_subgoal_fast_epoch\n"
     ]
    }
   ],
   "source": [
    "# make output dir\n",
    "if not os.path.isdir(args.dout):\n",
    "    os.makedirs(args.dout)\n",
    "\n",
    "print('args.out ', args.dout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tests_seen': 1533,\n",
      " 'tests_unseen': 1529,\n",
      " 'train': 21023,\n",
      " 'train_sanity': 250,\n",
      " 'train_sanity_v1': 250,\n",
      " 'valid_seen': 820,\n",
      " 'valid_seen_v1': 251,\n",
      " 'valid_unseen': 821,\n",
      " 'valid_unseen_v1': 255}\n"
     ]
    }
   ],
   "source": [
    "# load train/valid/tests splits\n",
    "with open(args.splits) as f:\n",
    "    splits = json.load(f)\n",
    "    pprint.pprint({k: len(v) for k, v in splits.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action_high': Vocab(93), 'word': Vocab(2360), 'action_low': Vocab(15)}\n"
     ]
    }
   ],
   "source": [
    "# preprocess and save -- only need to preprocess once\n",
    "if args.preprocess:\n",
    "    print(\"\\nPreprocessing dataset and saving to %s folders ... This will take a while. Do this once as required.\" % args.pp_folder)\n",
    "    dataset = Dataset(args, None)\n",
    "    dataset.preprocess_splits(splits)\n",
    "    vocab = torch.load(os.path.join(args.dout, \"%s.vocab\" % args.pp_folder))\n",
    "else:\n",
    "    vocab = torch.load(os.path.join(args.data, \"%s.vocab\" % args.pp_folder))\n",
    "    \n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model architecture\n",
    "args.gpu = False\n",
    "args.resume = None # os.path.join(args.dout, 'best_seen.pth')\n",
    "\n",
    "M = import_module('model.{}'.format(args.model))\n",
    "if args.resume:\n",
    "    print(\"Loading: \" + args.resume)\n",
    "    model, optimizer, start_epoch = M.Module.load(args.resume)\n",
    "    print(\"Restarting at epoch {}/{}\".format(start_epoch, args.epoch-1))\n",
    "    if start_epoch >= args.epoch:\n",
    "        print('Checkpoint already finished {}/{} epochs.'.format(start_epoch, args.epoch))\n",
    "        sys.exit(0)\n",
    "else:\n",
    "    model = M.Module(args, vocab)\n",
    "    optimizer = None\n",
    "    start_epoch = 0\n",
    "\n",
    "if args.gpu:\n",
    "    model = model.to(torch.device('cuda'))\n",
    "    if not optimizer is None:\n",
    "        optimizer_to(optimizer, torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Module(\n",
       "  (emb_word): Embedding(2360, 100)\n",
       "  (emb_action_low): Embedding(15, 100)\n",
       "  (enc): ActionFrameAttnEncoderPerSubgoal(\n",
       "    (emb): Embedding(15, 100)\n",
       "    (vis_dropout): Dropout(p=0.3, inplace=False)\n",
       "    (act_dropout): Dropout(p=0.0, inplace=True)\n",
       "    (vis_encoder): ResnetVisualEncoder(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (fc): Linear(in_features=3136, out_features=2500, bias=True)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (encoder): LSTM(2600, 512, batch_first=True, bidirectional=True)\n",
       "    (enc_att): SelfAttn(\n",
       "      (scorer): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dec): LanguageDecoder(\n",
       "    (emb): Embedding(2360, 100)\n",
       "    (cell): LSTMCell(1124, 1024)\n",
       "    (attn): DotAttn()\n",
       "    (input_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (hstate_dropout): Dropout(p=0.3, inplace=False)\n",
       "    (word_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (word): Linear(in_features=2148, out_features=100, bias=True)\n",
       "    (h_tm1_fc): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  )\n",
       "  (vis_dropout): Dropout(p=0.3, inplace=False)\n",
       "  (act_dropout): Dropout(p=0.0, inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine model layers\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   0%|          | 0/20 [00:00<?, ?it/s]\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A/root/data/home/hoyeung/alfred/models/model/seq2seq_per_subgoal.py:246: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  empty_tensor = torch.ones(torch.tensor(v[0][0][0]).unsqueeze(0).shape, device=device, dtype=torch.float if ('frames' in k) else torch.long) * self.pad\n",
      "/root/data/home/hoyeung/alfred/models/model/seq2seq_per_subgoal.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  seqs.append(torch.tensor(v[subgoal_i][batch_i], device=device, dtype=torch.float if ('frames' in k) else torch.long))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to: /root/data_alfred/exp/model:seq2seq_per_subgoal_fast_epoch\n",
      "> /root/data/home/hoyeung/alfred/models/model/seq2seq_per_subgoal.py(298)featurize()\n",
      "-> return feat, time_report\n",
      "(Pdb) q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch:   0%|          | 0/2 [00:03<?, ?it/s]\n",
      "epoch:   0%|          | 0/20 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2a79b170a1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# main training loop -- debug here if breakpoints were inserted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/data/home/hoyeung/alfred/models/model/seq2seq.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(self, splits, args, optimizer, start_epoch)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;31m# time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mepoch_loop_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterate_time_report\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m                 \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/home/hoyeung/alfred/models/model/seq2seq.py\u001b[0m in \u001b[0;36miterate\u001b[0;34m(self, data, batch_size)\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0;31m# time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m             \u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeaturize_time_report\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeaturize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0;31m# time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0mtime_report\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iterate_featurize'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/home/hoyeung/alfred/models/model/seq2seq_per_subgoal.py\u001b[0m in \u001b[0;36mfeaturize\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;31m# def serialize_lang_action(self, feat):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/home/hoyeung/alfred/models/model/seq2seq_per_subgoal.py\u001b[0m in \u001b[0;36mfeaturize\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;31m# def serialize_lang_action(self, feat):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# main training loop -- debug here if breakpoints were inserted\n",
    "model.run_train(splits, optimizer=optimizer, start_epoch=start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 5212\r\n",
      "-rwxr-xr-x 1 root root  540712 Apr 27 19:16 ann_0.json\r\n",
      "-rwxr-xr-x 1 root root  539252 Apr 27 19:16 ann_1.json\r\n",
      "-rwxr-xr-x 1 root root  540215 Apr 27 19:16 ann_2.json\r\n",
      "-rwxr-xr-x 1 root root  540221 Apr 27 19:16 ann_3.json\r\n",
      "-rw-r--r-- 1 root root   51724 May 13 18:30 extracted_feature_states.json\r\n",
      "-rw-r--r-- 1 root root 2663613 May 12 05:36 metadata_states.json\r\n",
      "-rw-r--r-- 1 root root  447729 May  5 07:55 subgoal_states.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l /root/data_alfred/json_feat_2.1.0/pick_two_obj_and_place-SprayBottle-None-Toilet-405/trial_T20190907_151132_176889/pp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/root/data_alfred/json_feat_2.1.0/valid_unseen/pick_two_obj_and_place-SprayBottle-None-Toilet-405/trial_T20190907_151132_176889'\n",
    "states_root = root.replace('train/', '').replace('valid_seen/', '').replace('valid_unseen/', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/data_alfred/json_feat_2.1.0/pick_two_obj_and_place-SprayBottle-None-Toilet-405/trial_T20190907_151132_176889'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/root/data_alfred/json_feat_2.1.0/valid_unseen/pick_two_obj_and_place-SprayBottle-None-Toilet-405/trial_T20190907_151132_176889'\n",
    "states_root = root.replace('train/', '').replace('valid_seen/', '').replace('valid_unseen/', '')\n",
    "with open(os.path.join(states_root, '{}/extracted_feature_states.json'.format(args.pp_folder)), 'r') as f:\n",
    "    obj_states = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['subgoal', 'subgoal_i', 'subgoal_t', 'overall_t', 'objectInstanceList', 'instance_visibile', 'instance_state_change', 'objectTypeList', 'type_visibile', 'type_state_change', 'metadata_path', 'root'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_states.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

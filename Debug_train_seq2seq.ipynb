{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training cycle debugging\n",
    "\n",
    "Basically run code copied from train_seq2seq.py in this notebook to catch bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['ALFRED_ROOT'] = '/home/hoyeung/alfred/'\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.environ['ALFRED_ROOT']))\n",
    "sys.path.append(os.path.join(os.environ['ALFRED_ROOT'], 'models'))\n",
    "\n",
    "# from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser\n",
    "import torch\n",
    "import pprint\n",
    "import json\n",
    "from data.preprocess import Dataset\n",
    "from importlib import import_module, reload\n",
    "from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser\n",
    "from models.utils.helper_utils import optimizer_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import these if we want to debug a model such as seq2seq_nl_baseline.py\n",
    "\n",
    "import torch\n",
    "import pprint\n",
    "import json\n",
    "from data.preprocess import Dataset\n",
    "from importlib import import_module, reload\n",
    "from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser\n",
    "from models.utils.helper_utils import optimizer_to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the default flags present in train_seq2seq.py\n",
    "\n",
    "parser = ArgumentParser(formatter_class=ArgumentDefaultsHelpFormatter)\n",
    "args = parser.parse_args('')\n",
    "\n",
    "# settings\n",
    "args.seed = 123\n",
    "args.data = 'data/json_feat_2.1.0'\n",
    "args.splits = 'data/splits/oct21.json'\n",
    "args.preprocess = False #!\n",
    "args.pp_folder = 'pp'\n",
    "args.save_every_epoch = False #!\n",
    "args.model = 'seq2seq_nl_baseline'\n",
    "args.gpu = True\n",
    "args.dout = 'exp/model:seq2seq_nl_baseline'\n",
    "args.resume = False #!\n",
    "\n",
    "# hyper parameters\n",
    "args.batch = 8\n",
    "args.epoch = 20\n",
    "args.lr = 1e-4\n",
    "args.decay_epoch = 10\n",
    "args.dhid = 512\n",
    "args.dframe = 2500\n",
    "args.demb = 100\n",
    "args.pframe = 300\n",
    "args.mask_loss_wt = 1.\n",
    "args.action_loss_wt = 1.\n",
    "args.subgoal_aux_loss_wt = 0.\n",
    "args.pm_aux_loss_wt = 0.\n",
    "\n",
    "# dropouts\n",
    "args.zero_goal = False #!\n",
    "args.zero_instr = False #!\n",
    "args.act_dropout = 0.\n",
    "args.lang_dropout = 0.\n",
    "args.input_dropout = 0.\n",
    "args.vis_dropout = 0.3\n",
    "args.hstate_dropout = 0.3\n",
    "args.attn_dropout = 0.\n",
    "args.actor_dropout = 0.\n",
    "args.word_dropout = 0.\n",
    "\n",
    "# other settings\n",
    "args.dec_teacher_forcing = False #!\n",
    "args.temp_no_history = False #!\n",
    "\n",
    "# debugging\n",
    "args.fast_epoch = False #!\n",
    "args.dataset_fraction = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite the default flags\n",
    "\n",
    "args.preprocess = False # Turn this to True if running for the first time\n",
    "\n",
    "args.model = 'seq2seq_nl_baseline'  # found under models/model/ directory\n",
    "args.dout = 'exp/model:seq2seq_nl_baseline'\n",
    "\n",
    "args.dec_teacher_forcing = True\n",
    "# args.gpu = False\n",
    "\n",
    "# light setup for debugging\n",
    "args.fast_epoch = True # Turn this to False if running for the first time to preprocess data properly\n",
    "args.epoch = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f39940f74f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and load data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.out  exp/model:seq2seq_nl_baseline\n"
     ]
    }
   ],
   "source": [
    "# make output dir\n",
    "if not os.path.isdir(args.dout):\n",
    "    os.makedirs(args.dout)\n",
    "\n",
    "print('args.out ', args.dout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tests_seen': 1533,\n",
      " 'tests_unseen': 1529,\n",
      " 'train': 21023,\n",
      " 'valid_seen': 820,\n",
      " 'valid_unseen': 821}\n"
     ]
    }
   ],
   "source": [
    "# load train/valid/tests splits\n",
    "with open(args.splits) as f:\n",
    "    splits = json.load(f)\n",
    "    pprint.pprint({k: len(v) for k, v in splits.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word': Vocab(2360), 'action_low': Vocab(15), 'action_high': Vocab(93)}\n"
     ]
    }
   ],
   "source": [
    "# preprocess and save -- only need to preprocess once\n",
    "if args.preprocess:\n",
    "    print(\"\\nPreprocessing dataset and saving to %s folders ... This will take a while. Do this once as required.\" % args.pp_folder)\n",
    "    dataset = Dataset(args, None)\n",
    "    dataset.preprocess_splits(splits)\n",
    "    vocab = torch.load(os.path.join(args.dout, \"%s.vocab\" % args.pp_folder))\n",
    "else:\n",
    "    vocab = torch.load(os.path.join(args.data, \"%s.vocab\" % args.pp_folder))\n",
    "    \n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model architecture\n",
    "args.gpu = False\n",
    "\n",
    "M = import_module('model.{}'.format(args.model))\n",
    "reload(M)\n",
    "model = M.Module(args, vocab)\n",
    "optimizer = None\n",
    "\n",
    "if args.gpu:\n",
    "    model = model.to(torch.device('cuda'))\n",
    "    if not optimizer is None:\n",
    "        optimizer_to(optimizer, torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Module(\n",
       "  (emb_word): Embedding(2360, 100)\n",
       "  (emb_action_low): Embedding(15, 100)\n",
       "  (enc): LSTM(100, 512, batch_first=True, bidirectional=True)\n",
       "  (enc_att): SelfAttn(\n",
       "    (scorer): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  )\n",
       "  (dec): LanguageDecoder(\n",
       "    (emb): Embedding(2360, 100)\n",
       "    (cell): LSTMCell(1124, 1024)\n",
       "    (attn): DotAttn()\n",
       "    (input_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (hstate_dropout): Dropout(p=0.3, inplace=False)\n",
       "    (word_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (word): Linear(in_features=2148, out_features=100, bias=True)\n",
       "    (h_tm1_fc): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  )\n",
       "  (act_dropout): Dropout(p=0.0, inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine model layers\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to: exp/model:seq2seq_nl_baseline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "batch:  50%|█████     | 1/2 [00:04<00:04,  4.31s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:09<00:00,  4.93s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:02<00:02,  2.50s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:05<00:00,  2.66s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:02<00:02,  2.72s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:05<00:00,  2.54s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found new best valid_seen!! Saving...\n",
      "Found new best valid_unseen!! Saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  50%|█████     | 1/2 [00:28<00:28, 28.53s/it]\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0,\n",
      " 'train': {'lang_instr_bleu': 5.444214570154877e-232,\n",
      "           'loss_lang_instr': 5.235116481781006,\n",
      "           'total_loss': 5.235116481781006},\n",
      " 'valid_seen': {'lang_instr_bleu': 1.1392305462353929e-156,\n",
      "                'loss_lang_instr': 4.714325189590454,\n",
      "                'total_loss': 4.714325189590454},\n",
      " 'valid_unseen': {'lang_instr_bleu': 5.048127627446426e-232,\n",
      "                  'loss_lang_instr': 4.025876998901367,\n",
      "                  'total_loss': 4.025876998901367}}\n",
      "epoch_time\t\t\t28.524\n",
      "forward_batch_train\t\t\t9.866\n",
      "forward_batch_valid_seen\t\t\t5.334\n",
      "forward_batch_valid_unseen\t\t\t5.094\n",
      "compute_metrics_valid_unseen\t\t\t4.352\n",
      "compute_metrics_valid_seen\t\t\t2.863\n",
      "compute_metrics_train\t\t\t0.403\n",
      "make_debug_train\t\t\t0.115\n",
      "make_debug_valid_seen\t\t\t0.112\n",
      "torch_save_valid_unseen\t\t\t0.112\n",
      "torch_save_valid_seen\t\t\t0.111\n",
      "torch_save_last\t\t\t0.108\n",
      "make_debug_valid_unseen\t\t\t0.051\n",
      "setup_time\t\t\t0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "batch:  50%|█████     | 1/2 [00:05<00:05,  5.03s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:10<00:00,  5.48s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:01<00:01,  1.67s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:01<00:01,  1.57s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found new best valid_seen!! Saving...\n",
      "Found new best valid_unseen!! Saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 100%|██████████| 2/2 [00:48<00:00, 24.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1,\n",
      " 'train': {'lang_instr_bleu': 7.760647204734706e-232,\n",
      "           'loss_lang_instr': 4.80204176902771,\n",
      "           'total_loss': 4.80204176902771},\n",
      " 'valid_seen': {'lang_instr_bleu': 9.296291086808552e-232,\n",
      "                'loss_lang_instr': 4.26695191860199,\n",
      "                'total_loss': 4.26695191860199},\n",
      " 'valid_unseen': {'lang_instr_bleu': 7.449444395162465e-232,\n",
      "                  'loss_lang_instr': 3.7604312896728516,\n",
      "                  'total_loss': 3.7604312896728516}}\n",
      "epoch_time\t\t\t48.272\n",
      "forward_batch_train\t\t\t20.829\n",
      "forward_batch_valid_seen\t\t\t8.669\n",
      "forward_batch_valid_unseen\t\t\t8.248\n",
      "compute_metrics_valid_unseen\t\t\t4.696\n",
      "compute_metrics_valid_seen\t\t\t3.231\n",
      "compute_metrics_train\t\t\t0.811\n",
      "torch_save_valid_seen\t\t\t0.765\n",
      "torch_save_valid_unseen\t\t\t0.261\n",
      "torch_save_last\t\t\t0.257\n",
      "make_debug_valid_unseen\t\t\t0.168\n",
      "make_debug_train\t\t\t0.166\n",
      "make_debug_valid_seen\t\t\t0.161\n",
      "setup_time\t\t\t0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# main training loop -- debug here if breakpoints were inserted\n",
    "model.run_train(splits, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at debugging outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 451936\r\n",
      "-rw-r--r-- 1 root root       453 Apr  8 01:23 best_seen.json\r\n",
      "-rw-r--r-- 1 root root 153981936 Apr  8 01:23 best_seen.pth\r\n",
      "-rw-r--r-- 1 root root       453 Apr  8 01:23 best_unseen.json\r\n",
      "-rw-r--r-- 1 root root 153981936 Apr  8 01:23 best_unseen.pth\r\n",
      "-rw-r--r-- 1 root root       843 Apr  8 01:22 config.json\r\n",
      "-rw-r--r-- 1 root root       250 Apr  7 23:56 events.out.tfevents.1586303655.3c556c990178\r\n",
      "-rw-r--r-- 1 root root       250 Apr  8 00:25 events.out.tfevents.1586305388.3c556c990178\r\n",
      "-rw-r--r-- 1 root root         0 Apr  8 00:24 events.out.tfevents.1586305447.3c556c990178\r\n",
      "-rw-r--r-- 1 root root       250 Apr  8 00:28 events.out.tfevents.1586305598.3c556c990178\r\n",
      "-rw-r--r-- 1 root root       250 Apr  8 00:37 events.out.tfevents.1586306114.3c556c990178\r\n",
      "-rw-r--r-- 1 root root      7108 Apr  8 01:14 events.out.tfevents.1586308348.3c556c990178\r\n",
      "-rw-r--r-- 1 root root      4095 Apr  8 01:23 events.out.tfevents.1586308974.3c556c990178\r\n",
      "-rw-r--r-- 1 root root 153981936 Apr  8 01:23 latest.pth\r\n",
      "-rw-r--r-- 1 root root     74711 Apr  7 23:39 pp.vocab\r\n",
      "-rw-r--r-- 1 root root     50914 Apr  8 01:23 train.debug_epoch_0.preds.json\r\n",
      "-rw-r--r-- 1 root root     38954 Apr  8 01:23 train.debug_epoch_1.preds.json\r\n",
      "-rw-r--r-- 1 root root     40473 Apr  8 01:23 train.debug_epoch_2.preds.json\r\n",
      "-rw-r--r-- 1 root root     40557 Apr  8 01:23 train.debug_epoch_3.preds.json\r\n",
      "-rw-r--r-- 1 root root     41247 Apr  8 01:23 train.debug_epoch_4.preds.json\r\n",
      "-rw-r--r-- 1 root root     52650 Apr  8 01:23 valid_seen.debug_epoch_0.preds.json\r\n",
      "-rw-r--r-- 1 root root     44509 Apr  8 01:23 valid_seen.debug_epoch_1.preds.json\r\n",
      "-rw-r--r-- 1 root root     46274 Apr  8 01:13 valid_seen.debug_epoch_2.preds.json\r\n",
      "-rw-r--r-- 1 root root     46247 Apr  8 01:23 valid_seen.debug_epoch_3.preds.json\r\n",
      "-rw-r--r-- 1 root root     47395 Apr  8 01:23 valid_seen.debug_epoch_4.preds.json\r\n",
      "-rw-r--r-- 1 root root     48622 Apr  8 01:23 valid_unseen.debug_epoch_0.preds.json\r\n",
      "-rw-r--r-- 1 root root     42847 Apr  8 01:23 valid_unseen.debug_epoch_1.preds.json\r\n",
      "-rw-r--r-- 1 root root     44406 Apr  8 01:13 valid_unseen.debug_epoch_2.preds.json\r\n",
      "-rw-r--r-- 1 root root     43182 Apr  8 01:23 valid_unseen.debug_epoch_3.preds.json\r\n",
      "-rw-r--r-- 1 root root     45286 Apr  8 01:23 valid_unseen.debug_epoch_4.preds.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l exp/model:seq2seq_nl_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 4\n",
    "\n",
    "with open(os.path.join(args.dout, 'valid_unseen.debug_epoch_{}.preds.json'.format(epoch)), 'r') as f:\n",
    "    debug_tr = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print(type(debug_tr))\n",
    "print(len(debug_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['trial_T20190908_044113_026049_0', 'trial_T20190907_020258_749030_0', 'trial_T20190909_061130_844814_0', 'trial_T20190907_155006_533262_0', 'trial_T20190906_191501_563086_0', 'trial_T20190912_221141_608117_0', 'trial_T20190909_061838_159982_0', 'trial_T20190908_145356_918528_0', 'trial_T20190907_171035_866841_0', 'trial_T20190907_161235_786153_0', 'trial_T20190907_133953_562557_0', 'trial_T20190907_171933_349922_0', 'trial_T20190908_032518_891433_0', 'trial_T20190909_120632_691361_0', 'trial_T20190907_221208_560499_0', 'trial_T20190908_073749_086690_0'])\n"
     ]
    }
   ],
   "source": [
    "# all the task numbers\n",
    "print(debug_tr.keys())\n",
    "# let's look at one of them below\n",
    "task_num = 'trial_T20190907_155006_533262_0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lang_goal', 'lang_instr', 'action_low', 'action_high', 'p_lang_instr'])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We log these from each task\n",
    "debug_tr[task_num].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Put a washed bowl away in a kitchen cabinet.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gold goal description\n",
    "debug_tr[task_num]['lang_goal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Turn left, then go clockwise to face the opposite end of the kitchen island.',\n",
       " 'Pick up the bowl that is near the potted plant in the corner of the island.',\n",
       " 'Turn right and go counterclockwise around the island to the sink.',\n",
       " 'Wash the bowl in the sink.',\n",
       " 'Face the opposite direction and look up at the cabinets above the counter to the left of the stove.',\n",
       " 'Put the bowl on the bottom shelf of the cabinet on the right.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gold low-level instruction description\n",
    "debug_tr[task_num]['lang_instr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LookDown_15',\n",
       " 'RotateLeft_90',\n",
       " 'MoveAhead_25',\n",
       " 'MoveAhead_25',\n",
       " 'RotateRight_90',\n",
       " 'MoveAhead_25',\n",
       " 'MoveAhead_25',\n",
       " 'MoveAhead_25',\n",
       " 'MoveAhead_25',\n",
       " 'MoveAhead_25',\n",
       " 'MoveAhead_25',\n",
       " 'RotateRight_90',\n",
       " 'LookDown_15',\n",
       " 'PickupObject',\n",
       " 'LookUp_15',\n",
       " 'RotateLeft_90',\n",
       " 'MoveAhead_25',\n",
       " 'MoveAhead_25',\n",
       " 'RotateLeft_90',\n",
       " 'MoveAhead_25',\n",
       " 'LookUp_15',\n",
       " 'LookUp_15',\n",
       " 'LookUp_15',\n",
       " 'OpenObject',\n",
       " 'PutObject',\n",
       " 'CloseObject',\n",
       " 'ToggleObjectOn',\n",
       " 'ToggleObjectOff',\n",
       " 'OpenObject',\n",
       " 'PickupObject',\n",
       " 'CloseObject',\n",
       " 'LookDown_15',\n",
       " 'LookDown_15',\n",
       " 'LookDown_15',\n",
       " 'RotateLeft_90',\n",
       " 'MoveAhead_25',\n",
       " 'MoveAhead_25',\n",
       " 'RotateLeft_90',\n",
       " 'MoveAhead_25',\n",
       " 'PutObject']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gold Input low-level action description\n",
    "debug_tr[task_num]['action_low']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GotoLocation',\n",
       " 'PickupObject',\n",
       " 'GotoLocation',\n",
       " 'HeatObject',\n",
       " 'GotoLocation',\n",
       " 'PutObject',\n",
       " 'NoOp']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gold Input high-level subgoal action description\n",
    "debug_tr[task_num]['action_high']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the cater faces tilt combo corner hearth let pick mixing running freezer . vase bathrub organizer flattest reuse spring the hutch flattest spaces organize study coach puts bringing tiny passed sprayers toilets the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker the hutch coffeemaker'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction result\n",
    "debug_tr[task_num]['p_lang_instr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

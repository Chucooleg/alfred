{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training cycle debugging\n",
    "\n",
    "Basically run code copied from train_seq2seq.py in this notebook to catch bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['ALFRED_ROOT'] = '/root/data/home/hoyeung/alfred/'\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.environ['ALFRED_ROOT']))\n",
    "sys.path.append(os.path.join(os.environ['ALFRED_ROOT'], 'models'))\n",
    "\n",
    "# from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser\n",
    "import torch\n",
    "import pprint\n",
    "import json\n",
    "from data.preprocess import Dataset\n",
    "from importlib import import_module, reload\n",
    "from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser\n",
    "from models.utils.helper_utils import optimizer_to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the default flags present in train_seq2seq.py\n",
    "\n",
    "parser = ArgumentParser(formatter_class=ArgumentDefaultsHelpFormatter)\n",
    "args = parser.parse_args('')\n",
    "\n",
    "# settings\n",
    "args.seed = 123\n",
    "args.data = '/root/data_alfred/json_feat_2.1.0'\n",
    "args.splits = '/root/data_alfred/splits/may17.json'\n",
    "args.object_vocab = 'objects_20200522'\n",
    "args.preprocess = False #!\n",
    "args.pp_folder = 'pp'\n",
    "args.monitor_train_every = 10\n",
    "args.save_every_epoch = False #!\n",
    "args.model = 'seq2seq_per_subgoal'\n",
    "args.gpu = True\n",
    "args.dout = 'exp/model:seq2seq_per_subgoal'\n",
    "args.resume = False #!\n",
    "\n",
    "# hyper parameters\n",
    "args.batch = 8\n",
    "args.epoch = 20\n",
    "args.lr = 1e-4\n",
    "args.decay_epoch = 10\n",
    "args.dhid = 512\n",
    "args.dframe = 2500\n",
    "args.demb = 100\n",
    "args.pframe = 300\n",
    "args.mask_loss_wt = 1.\n",
    "args.action_loss_wt = 1.\n",
    "args.subgoal_aux_loss_wt = 0.\n",
    "args.pm_aux_loss_wt = 0.\n",
    "\n",
    "# architecture ablations\n",
    "# args.maxpool_over_object_states = False\n",
    "# args.aux_loss_over_object_states = False\n",
    "args.encoder_addons = 'none'\n",
    "args.decoder_addons = 'none'\n",
    "args.object_repr = 'type'\n",
    "args.reweight_aux_bce = False\n",
    "\n",
    "# dropouts\n",
    "args.zero_goal = False #!\n",
    "args.zero_instr = False #!\n",
    "args.act_dropout = 0.\n",
    "args.lang_dropout = 0.\n",
    "args.input_dropout = 0.\n",
    "args.vis_dropout = 0.3\n",
    "args.hstate_dropout = 0.3\n",
    "args.attn_dropout = 0.\n",
    "args.actor_dropout = 0.\n",
    "args.word_dropout = 0.\n",
    "\n",
    "# other settings\n",
    "args.train_teacher_forcing = False #!\n",
    "args.train_student_forcing_prob = 0.1\n",
    "args.temp_no_history = False #!\n",
    "\n",
    "# debugging\n",
    "args.fast_epoch = False #!\n",
    "args.dataset_fraction = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite the default flags\n",
    "\n",
    "args.preprocess = False # Turn this to True if running for the first time\n",
    "\n",
    "args.model = 'seq2seq_per_subgoal'  # found under models/model/ directory\n",
    "args.dout = '/root/data_alfred/exp/model:seq2seq_per_subgoal_biattn_instance_fast_epoch'\n",
    "\n",
    "args.train_teacher_forcing = True\n",
    "args.gpu = False\n",
    "\n",
    "# light setup for debugging\n",
    "args.fast_epoch = True # Turn this to False if running for the first time to preprocess data properly\n",
    "args.epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.maxpool_over_object_states = True\n",
    "# args.aux_loss_over_object_states = True\n",
    "\n",
    "args.encoder_addons = 'biattn_obj'\n",
    "args.decoder_addons = 'aux_loss'\n",
    "args.object_repr = 'instance'\n",
    "args.reweight_aux_bce = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f724809d5d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and load data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.out  /root/data_alfred/exp/model:seq2seq_per_subgoal_biattn_instance_fast_epoch\n"
     ]
    }
   ],
   "source": [
    "# make output dir\n",
    "if not os.path.isdir(args.dout):\n",
    "    os.makedirs(args.dout)\n",
    "\n",
    "print('args.out ', args.dout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tests_seen': 1533,\n",
      " 'tests_unseen': 1529,\n",
      " 'train': 20806,\n",
      " 'train_sanity': 246,\n",
      " 'train_sanity_v1': 246,\n",
      " 'valid_seen': 814,\n",
      " 'valid_seen_v1': 249,\n",
      " 'valid_unseen': 818,\n",
      " 'valid_unseen_v1': 254}\n"
     ]
    }
   ],
   "source": [
    "# load train/valid/tests splits\n",
    "with open(args.splits) as f:\n",
    "    splits = json.load(f)\n",
    "    pprint.pprint({k: len(v) for k, v in splits.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action_high': Vocab(93), 'word': Vocab(2360), 'action_low': Vocab(15)}\n"
     ]
    }
   ],
   "source": [
    "# preprocess and save -- only need to preprocess once\n",
    "if args.preprocess:\n",
    "    print(\"\\nPreprocessing dataset and saving to %s folders ... This will take a while. Do this once as required.\" % args.pp_folder)\n",
    "    dataset = Dataset(args, None)\n",
    "    dataset.preprocess_splits(splits)\n",
    "    vocab = torch.load(os.path.join(args.dout, \"%s.vocab\" % args.pp_folder))\n",
    "else:\n",
    "    vocab = torch.load(os.path.join(args.data, \"%s.vocab\" % args.pp_folder))\n",
    "    \n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_vocab = torch.load(os.path.join(args.data, '%s.vocab' % args.object_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model architecture\n",
    "args.gpu = False\n",
    "args.resume = None # os.path.join(args.dout, 'best_seen.pth')\n",
    "\n",
    "M = import_module('model.{}'.format(args.model))\n",
    "if args.resume:\n",
    "    print(\"Loading: \" + args.resume)\n",
    "    model, optimizer, start_epoch = M.Module.load(args.resume)\n",
    "    print(\"Restarting at epoch {}/{}\".format(start_epoch, args.epoch-1))\n",
    "    if start_epoch >= args.epoch:\n",
    "        print('Checkpoint already finished {}/{} epochs.'.format(start_epoch, args.epoch))\n",
    "        sys.exit(0)\n",
    "else:\n",
    "    model = M.Module(args, vocab, object_vocab)\n",
    "    optimizer = None\n",
    "    start_epoch = 0\n",
    "\n",
    "if args.gpu:\n",
    "    model = model.to(torch.device('cuda'))\n",
    "    if not optimizer is None:\n",
    "        optimizer_to(optimizer, torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Module(\n",
       "  (emb_word): Embedding(2360, 100)\n",
       "  (emb_action_low): Embedding(15, 100)\n",
       "  (emb_object): Embedding(111, 100, padding_idx=0)\n",
       "  (instance_fc): Linear(in_features=201, out_features=512, bias=True)\n",
       "  (enc): ActionFrameAttnEncoderPerSubgoalObjAttn(\n",
       "    (emb): Embedding(15, 100)\n",
       "    (vis_dropout): Dropout(p=0.3, inplace=False)\n",
       "    (act_dropout): Dropout(p=0.0, inplace=True)\n",
       "    (vis_encoder): ResnetVisualEncoder(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (fc): Linear(in_features=3136, out_features=2500, bias=True)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (enc_att): SelfAttn(\n",
       "      (scorer): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    )\n",
       "    (encoder): LSTM(2600, 512, batch_first=True, bidirectional=True)\n",
       "    (input_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (hstate_dropout): Dropout(p=0.3, inplace=False)\n",
       "    (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (obj_emb): Embedding(111, 100, padding_idx=0)\n",
       "    (instance_fc): Linear(in_features=201, out_features=512, bias=True)\n",
       "    (obj_attn): DotSigmoidAttn()\n",
       "    (h_tm1_fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (forward_cell): LSTMCell(3624, 512)\n",
       "    (backward_cell): LSTMCell(3624, 512)\n",
       "  )\n",
       "  (dec): LanguageDecoder(\n",
       "    (emb): Embedding(2360, 100)\n",
       "    (obj_emb): Embedding(111, 100, padding_idx=0)\n",
       "    (cell): LSTMCell(1124, 1024)\n",
       "    (attn): DotAttn()\n",
       "    (input_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (hstate_dropout): Dropout(p=0.3, inplace=False)\n",
       "    (word_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (word): Linear(in_features=2148, out_features=100, bias=True)\n",
       "    (h_tm1_fc): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (h_enc_fc): Linear(in_features=1, out_features=2, bias=True)\n",
       "    (instance_fc): Linear(in_features=201, out_features=512, bias=True)\n",
       "  )\n",
       "  (vis_dropout): Dropout(p=0.3, inplace=False)\n",
       "  (act_dropout): Dropout(p=0.0, inplace=True)\n",
       "  (aux_criterion): BCEWithLogitsLoss()\n",
       "  (language_crtierion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine model layers\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   0%|          | 0/50 [00:00<?, ?it/s]\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to: /root/data_alfred/exp/model:seq2seq_per_subgoal_biattn_instance_fast_epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/data/home/hoyeung/alfred/models/model/seq2seq_per_subgoal.py:297: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  empty_tensor = torch.ones(torch.tensor(v[0][0][0]).unsqueeze(0).shape, device=device, dtype=torch.float if ('frames' in k) else torch.long) * self.pad\n",
      "/root/data/home/hoyeung/alfred/models/model/seq2seq_per_subgoal.py:308: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  seqs.append(torch.tensor(v[subgoal_i][batch_i], device=device, dtype=torch.float if ('frames' in k) else torch.long))\n",
      "\n",
      "batch:  50%|█████     | 1/2 [00:16<00:16, 16.84s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:35<00:00, 17.51s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:03<00:03,  3.85s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:05<00:00,  2.85s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:04<00:04,  4.25s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:15<00:00,  7.66s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:04<00:04,  4.69s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:12<00:00,  6.10s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:19<00:19, 19.59s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:29<00:00, 14.69s/it]\u001b[A\n",
      "/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:24<00:24, 24.50s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:45<00:00, 22.51s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:20<00:20, 20.46s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:43<00:00, 21.55s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found new best valid_seen!! Saving...\n",
      "Found new best valid_unseen!! Saving...\n",
      "Found new best train_sanity!! Saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   2%|▏         | 1/50 [03:17<2:41:02, 197.20s/it]\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0,\n",
      " 'train_sanity': {'BLEU': 2.150927457282457e-232,\n",
      "                  'perplexity': 262.3821563720703,\n",
      "                  'total_loss': 1471.2233238220215},\n",
      " 'valid_seen': {'BLEU': 2.575713873220704e-232,\n",
      "                'perplexity': 279.86607360839844,\n",
      "                'total_loss': 1694.620002746582},\n",
      " 'valid_unseen': {'BLEU': 2.656039007870951e-232,\n",
      "                  'perplexity': 283.98423767089844,\n",
      "                  'total_loss': 115.86846160888672}}\n",
      "epoch_time                    197.196                                 \n",
      "compute_metrics_validation_sets158.658                                 \n",
      "forward_batch_train_with_iterate35.02                                   \n",
      "forward_batch_train           34.605                                  \n",
      "torch_save_valid_seen         1.91                                    \n",
      "torch_save_valid_unseen       0.461                                   \n",
      "iterate_featurize             0.436                                   \n",
      "torch_save_last               0.362                                   \n",
      "torch_save_train_sanity       0.321                                   \n",
      "featurize_tensorization_and_padding0.23                                    \n",
      "iterate_load_task_json        0.193                                   \n",
      "make_debug_valid_unseen       0.162                                   \n",
      "make_debug_valid_seen         0.159                                   \n",
      "make_debug_train              0.14                                    \n",
      "featurize_input_resnet_features0.137                                   \n",
      "featurize_torch_load_time     0.082                                   \n",
      "setup_time                    0.001                                   \n",
      "featurize_outputs             0.001                                   \n",
      "featurize_input_action_low    0.0                                     \n",
      "compute_metrics_train         0.0                                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "batch:  50%|█████     | 1/2 [00:18<00:18, 18.58s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:34<00:00, 17.09s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:04<00:04,  4.76s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:06<00:00,  3.36s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:04<00:04,  4.58s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:09<00:00,  4.59s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:04<00:04,  4.08s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:07<00:00,  3.89s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:17<00:17, 17.89s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:27<00:00, 13.89s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:23<00:23, 23.62s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:43<00:00, 21.82s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:20<00:20, 20.14s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:40<00:00, 20.10s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found new best valid_seen!! Saving...\n",
      "Found new best valid_unseen!! Saving...\n",
      "Found new best train_sanity!! Saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   4%|▍         | 2/50 [06:26<2:35:51, 194.83s/it]\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1,\n",
      " 'train_sanity': {'BLEU': 3.0002294792922473e-232,\n",
      "                  'perplexity': 147.49627685546875,\n",
      "                  'total_loss': 3726.3920612335205},\n",
      " 'valid_seen': {'BLEU': 3.552694461707597e-232,\n",
      "                'perplexity': 160.00331115722656,\n",
      "                'total_loss': 4326.737593173981},\n",
      " 'valid_unseen': {'BLEU': 3.5704321450811896e-232,\n",
      "                  'perplexity': 155.53447723388672,\n",
      "                  'total_loss': 11.868228912353516}}\n",
      "epoch_time                    386.499                                 \n",
      "compute_metrics_validation_sets296.367                                 \n",
      "forward_batch_train_with_iterate69.208                                  \n",
      "forward_batch_train           68.343                                  \n",
      "torch_save_last               7.305                                   \n",
      "torch_save_valid_seen         6.82                                    \n",
      "torch_save_valid_unseen       3.85                                    \n",
      "torch_save_train_sanity       2.028                                   \n",
      "iterate_featurize             0.879                                   \n",
      "featurize_tensorization_and_padding0.487                                   \n",
      "iterate_load_task_json        0.414                                   \n",
      "make_debug_valid_unseen       0.339                                   \n",
      "make_debug_train              0.296                                   \n",
      "make_debug_valid_seen         0.277                                   \n",
      "featurize_input_resnet_features0.249                                   \n",
      "featurize_torch_load_time     0.144                                   \n",
      "featurize_outputs             0.002                                   \n",
      "setup_time                    0.001                                   \n",
      "featurize_input_action_low    0.001                                   \n",
      "compute_metrics_train         0.001                                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "batch:  50%|█████     | 1/2 [00:24<00:24, 24.24s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:41<00:00, 20.74s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:05<00:05,  5.66s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:09<00:00,  4.80s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:07<00:07,  7.65s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:12<00:00,  6.32s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:07<00:07,  7.13s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:12<00:00,  6.35s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:40<00:40, 40.34s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:50<00:00, 25.34s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:39<00:39, 39.43s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [01:23<00:00, 41.55s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [01:19<01:19, 79.11s/it]\u001b[A\n",
      "epoch:   4%|▍         | 2/50 [11:17<4:31:01, 338.78s/it]\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# main training loop -- debug here if breakpoints were inserted\n",
    "model.run_train(splits, optimizer=optimizer, start_epoch=start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/root/data_alfred/exp/model:seq2seq_per_subgoal_biattn_instance_fast_epoch/train_sanity.debug_epoch_0.preds.json', 'r') as f:\n",
    "    debug_dat = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['root', 'action_low', 'action_high', 'p_lang_instr', 'obj_token_id', 'p_obj_vis', 'p_state_change', 'l_obj_vis', 'l_state_change'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_dat['trial_T20190907_200104_945677_0'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': [0.0691295862197876,\n",
       "  0.31164777278900146,\n",
       "  0.9970205426216125,\n",
       "  0.015615975484251976,\n",
       "  0.014363543130457401,\n",
       "  0.17510473728179932,\n",
       "  0.0005708530079573393,\n",
       "  0.08195849508047104,\n",
       "  0.9996793270111084,\n",
       "  0.9995750784873962,\n",
       "  0.9997149109840393,\n",
       "  0.9995577931404114,\n",
       "  0.9995660185813904,\n",
       "  0.9997116923332214,\n",
       "  0.9995922446250916,\n",
       "  0.999503493309021,\n",
       "  0.9993239641189575,\n",
       "  0.9991711378097534,\n",
       "  0.9988883137702942,\n",
       "  0.9985225796699524,\n",
       "  0.9984582662582397,\n",
       "  0.49693214893341064,\n",
       "  0.6733318567276001,\n",
       "  0.6518407464027405,\n",
       "  0.4758867025375366,\n",
       "  0.3146660625934601,\n",
       "  0.9996658563613892,\n",
       "  2.830060475389473e-05,\n",
       "  9.804693945625331e-06,\n",
       "  0.06095347926020622,\n",
       "  0.9994327425956726,\n",
       "  9.529480303172022e-05,\n",
       "  4.818804154638201e-05,\n",
       "  0.999860405921936,\n",
       "  0.9998681545257568,\n",
       "  0.9996261596679688,\n",
       "  0.9994298815727234,\n",
       "  0.903156042098999,\n",
       "  0.9140000343322754,\n",
       "  0.0016576650086790323,\n",
       "  0.5512198805809021,\n",
       "  0.819766640663147,\n",
       "  0.6092637181282043,\n",
       "  0.9517333507537842,\n",
       "  0.000520942616276443,\n",
       "  0.9975778460502625,\n",
       "  0.9999901056289673,\n",
       "  0.9999881982803345,\n",
       "  0.9691734313964844,\n",
       "  0.9966028928756714,\n",
       "  7.18662267900072e-05,\n",
       "  4.992914182366803e-05,\n",
       "  0.9999120235443115,\n",
       "  0.9999490976333618,\n",
       "  5.098803285363829e-06,\n",
       "  2.25736694119405e-05,\n",
       "  0.4265342354774475,\n",
       "  3.0968345527071506e-05,\n",
       "  4.887567774858326e-05,\n",
       "  3.941554041375639e-06,\n",
       "  0.8014389872550964,\n",
       "  0.16050739586353302,\n",
       "  8.345843411916576e-07,\n",
       "  5.249897867543041e-07,\n",
       "  0.0032142726704478264,\n",
       "  0.0033655038569122553,\n",
       "  0.003414764767512679,\n",
       "  0.0003483270120341331,\n",
       "  0.273912638425827,\n",
       "  0.0005689778481610119,\n",
       "  4.238359940789138e-10,\n",
       "  4.858682345343368e-10,\n",
       "  0.5529109239578247,\n",
       "  0.9238399267196655,\n",
       "  0.9974414110183716,\n",
       "  0.15224574506282806,\n",
       "  0.130961075425148,\n",
       "  0.1543019860982895,\n",
       "  0.13252167403697968,\n",
       "  0.9999814033508301,\n",
       "  0.9999816417694092,\n",
       "  0.9999817609786987,\n",
       "  0.9999817609786987,\n",
       "  7.231222298287321e-06,\n",
       "  8.992313814815134e-05,\n",
       "  7.897889736341313e-05,\n",
       "  7.970660226419568e-05,\n",
       "  0.0002342631050851196,\n",
       "  0.0014733199495822191,\n",
       "  0.0001285650214413181,\n",
       "  1.0,\n",
       "  0.9999998807907104,\n",
       "  0.8074412941932678,\n",
       "  4.334372533776332e-06,\n",
       "  0.8680204749107361],\n",
       " '1': [0.08821336179971695,\n",
       "  0.7516499161720276,\n",
       "  0.99774169921875,\n",
       "  0.015776140615344048,\n",
       "  0.015007386915385723,\n",
       "  0.39988255500793457,\n",
       "  0.0018405249575152993,\n",
       "  0.25880444049835205,\n",
       "  0.9997288584709167,\n",
       "  0.9996919631958008,\n",
       "  0.9997590184211731,\n",
       "  0.9996891021728516,\n",
       "  0.9997034668922424,\n",
       "  0.9997807145118713,\n",
       "  0.9997232556343079,\n",
       "  0.9996252059936523,\n",
       "  0.9995635151863098,\n",
       "  0.9994805455207825,\n",
       "  0.9993988275527954,\n",
       "  0.9992838501930237,\n",
       "  0.9992828965187073,\n",
       "  0.8710656762123108,\n",
       "  0.9223238229751587,\n",
       "  0.9229228496551514,\n",
       "  0.8696271777153015,\n",
       "  0.8177435398101807,\n",
       "  0.9996800422668457,\n",
       "  4.8706082452554256e-05,\n",
       "  1.8451810319675133e-05,\n",
       "  0.16128630936145782,\n",
       "  0.9999109506607056,\n",
       "  0.00017435953486710787,\n",
       "  9.000222780741751e-05,\n",
       "  0.9999405145645142,\n",
       "  0.9999494552612305,\n",
       "  0.9998726844787598,\n",
       "  0.9998455047607422,\n",
       "  0.9299586415290833,\n",
       "  0.9347663521766663,\n",
       "  0.0023980995174497366,\n",
       "  0.7241100668907166,\n",
       "  0.9233611822128296,\n",
       "  0.8149365186691284,\n",
       "  0.9811534881591797,\n",
       "  0.0005744943046011031,\n",
       "  0.9995775818824768,\n",
       "  0.9999954700469971,\n",
       "  0.9999949932098389,\n",
       "  0.9858478307723999,\n",
       "  0.999019980430603,\n",
       "  0.0003532844712026417,\n",
       "  0.00028917548479512334,\n",
       "  0.9999613761901855,\n",
       "  0.9999837875366211,\n",
       "  6.766713795514079e-06,\n",
       "  6.201831274665892e-05,\n",
       "  0.5931091904640198,\n",
       "  0.00010013358405558392,\n",
       "  0.0002072339557344094,\n",
       "  2.9738198463746812e-06,\n",
       "  0.9047741293907166,\n",
       "  0.33694714307785034,\n",
       "  3.289407686679624e-06,\n",
       "  2.351414423173992e-06,\n",
       "  0.014187604188919067,\n",
       "  0.014524947851896286,\n",
       "  0.01463235355913639,\n",
       "  0.0009298920049332082,\n",
       "  0.552869975566864,\n",
       "  0.0010357719147577882,\n",
       "  6.916494599273904e-10,\n",
       "  7.344925223584653e-10,\n",
       "  0.7884917855262756,\n",
       "  0.9632057547569275,\n",
       "  0.9994947910308838,\n",
       "  0.3246253728866577,\n",
       "  0.3064245283603668,\n",
       "  0.33792269229888916,\n",
       "  0.3162493407726288,\n",
       "  0.9999910593032837,\n",
       "  0.9999912977218628,\n",
       "  0.9999915361404419,\n",
       "  0.999991774559021,\n",
       "  2.225942625955213e-05,\n",
       "  0.00012141898332629353,\n",
       "  0.0001573876361362636,\n",
       "  0.0001128783987951465,\n",
       "  0.000419448537286371,\n",
       "  0.00445600925013423,\n",
       "  0.00026302709011361003,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9999438524246216,\n",
       "  2.3374772354145534e-05,\n",
       "  0.9772312641143799],\n",
       " '2': [0.027965480461716652,\n",
       "  0.02049526944756508,\n",
       "  0.9930203557014465,\n",
       "  0.009978815913200378,\n",
       "  0.008943434804677963,\n",
       "  0.030366847291588783,\n",
       "  0.0002688535023480654,\n",
       "  0.009013649076223373,\n",
       "  0.9991045594215393,\n",
       "  0.9988176226615906,\n",
       "  0.9993077516555786,\n",
       "  0.9987937211990356,\n",
       "  0.9989122152328491,\n",
       "  0.9994363188743591,\n",
       "  0.9990643858909607,\n",
       "  0.9981885552406311,\n",
       "  0.9974762797355652,\n",
       "  0.996315062046051,\n",
       "  0.9949389696121216,\n",
       "  0.9926042556762695,\n",
       "  0.9925845265388489,\n",
       "  0.3440078794956207,\n",
       "  0.641904890537262,\n",
       "  0.6460961699485779,\n",
       "  0.33776748180389404,\n",
       "  0.1768958568572998,\n",
       "  0.9996639490127563,\n",
       "  3.292023393441923e-05,\n",
       "  3.968923465436092e-06,\n",
       "  0.05203055962920189,\n",
       "  0.9982896447181702,\n",
       "  0.0002516652748454362,\n",
       "  5.954942389507778e-05,\n",
       "  0.999855637550354,\n",
       "  0.9998986721038818,\n",
       "  0.9992421865463257,\n",
       "  0.9988435506820679,\n",
       "  0.7570807337760925,\n",
       "  0.7863345742225647,\n",
       "  0.0020070241298526525,\n",
       "  0.43490713834762573,\n",
       "  0.8575120568275452,\n",
       "  0.4015651345252991,\n",
       "  0.8416959047317505,\n",
       "  0.00020403478993102908,\n",
       "  0.9916419982910156,\n",
       "  0.9999935626983643,\n",
       "  0.9999920129776001,\n",
       "  0.9618475437164307,\n",
       "  0.9816123843193054,\n",
       "  1.7718413801048882e-05,\n",
       "  1.1450472811702639e-05,\n",
       "  0.9998737573623657,\n",
       "  0.9999610185623169,\n",
       "  4.243389867042424e-06,\n",
       "  3.240847945562564e-06,\n",
       "  0.7205311059951782,\n",
       "  2.6238267309963703e-05,\n",
       "  6.935642431926681e-06,\n",
       "  3.87743102692184e-06,\n",
       "  0.6509042382240295,\n",
       "  0.4460291564464569,\n",
       "  3.5446557831164682e-06,\n",
       "  1.7053698684321716e-06,\n",
       "  0.006496804766356945,\n",
       "  0.0068409256637096405,\n",
       "  0.006952582858502865,\n",
       "  0.00038864699308760464,\n",
       "  0.19672103226184845,\n",
       "  0.0006097775767557323,\n",
       "  8.055567324305457e-10,\n",
       "  9.18312759168316e-10,\n",
       "  0.3807285726070404,\n",
       "  0.913465142250061,\n",
       "  0.9982378482818604,\n",
       "  0.16392093896865845,\n",
       "  0.1402689814567566,\n",
       "  0.18264922499656677,\n",
       "  0.1527516096830368,\n",
       "  0.9999816417694092,\n",
       "  0.9999829530715942,\n",
       "  0.9999839067459106,\n",
       "  0.999984622001648,\n",
       "  2.0790244889212772e-05,\n",
       "  0.00010988914436893538,\n",
       "  0.00010332691454095766,\n",
       "  9.37374061322771e-05,\n",
       "  0.0001632704515941441,\n",
       "  0.00017353950534015894,\n",
       "  5.902779957978055e-05,\n",
       "  1.0,\n",
       "  0.9999996423721313,\n",
       "  0.999904990196228,\n",
       "  4.2227934500260744e-06,\n",
       "  0.5634357929229736],\n",
       " '3': [0.05275341868400574,\n",
       "  0.6808644533157349,\n",
       "  0.997878909111023,\n",
       "  0.01275054644793272,\n",
       "  0.011488615535199642,\n",
       "  0.28855374455451965,\n",
       "  0.0013709381455555558,\n",
       "  0.1687343269586563,\n",
       "  0.9992978572845459,\n",
       "  0.9992141723632812,\n",
       "  0.9993688464164734,\n",
       "  0.9992417097091675,\n",
       "  0.9993164539337158,\n",
       "  0.999479353427887,\n",
       "  0.9993717074394226,\n",
       "  0.9990584254264832,\n",
       "  0.9988852143287659,\n",
       "  0.9987121820449829,\n",
       "  0.9984700083732605,\n",
       "  0.9981755018234253,\n",
       "  0.9980840682983398,\n",
       "  0.7934763431549072,\n",
       "  0.8023133277893066,\n",
       "  0.78263258934021,\n",
       "  0.7584120631217957,\n",
       "  0.6820194125175476,\n",
       "  0.9997921586036682,\n",
       "  4.554404586087912e-05,\n",
       "  1.992660509131383e-05,\n",
       "  0.19192709028720856,\n",
       "  0.999919056892395,\n",
       "  0.00021087781351525337,\n",
       "  0.0001115108243538998,\n",
       "  0.9999097585678101,\n",
       "  0.9999271631240845,\n",
       "  0.9998311996459961,\n",
       "  0.9997764229774475,\n",
       "  0.8923572897911072,\n",
       "  0.89618319272995,\n",
       "  0.0017867395654320717,\n",
       "  0.46912646293640137,\n",
       "  0.9108062982559204,\n",
       "  0.8156676888465881,\n",
       "  0.9777071475982666,\n",
       "  0.0006240829825401306,\n",
       "  0.9990654587745667,\n",
       "  0.9999898672103882,\n",
       "  0.9999887943267822,\n",
       "  0.9929587841033936,\n",
       "  0.9993730187416077,\n",
       "  0.0002706202503759414,\n",
       "  0.00021204398944973946,\n",
       "  0.9999593496322632,\n",
       "  0.9999566078186035,\n",
       "  8.621100278105587e-06,\n",
       "  6.732984184054658e-05,\n",
       "  0.5207172632217407,\n",
       "  0.00010291775106452405,\n",
       "  0.00016446624067611992,\n",
       "  4.689241450250847e-06,\n",
       "  0.9139959216117859,\n",
       "  0.2742636203765869,\n",
       "  6.12829410329141e-07,\n",
       "  4.3744896061070904e-07,\n",
       "  0.024292560294270515,\n",
       "  0.025732679292559624,\n",
       "  0.0262258630245924,\n",
       "  0.00047302531311288476,\n",
       "  0.23513804376125336,\n",
       "  0.0003759216924663633,\n",
       "  6.631323268280198e-10,\n",
       "  7.175874894294054e-10,\n",
       "  0.7764150500297546,\n",
       "  0.9817357659339905,\n",
       "  0.9995375871658325,\n",
       "  0.18556922674179077,\n",
       "  0.17150750756263733,\n",
       "  0.1966213583946228,\n",
       "  0.18109773099422455,\n",
       "  0.9999619722366333,\n",
       "  0.9999630451202393,\n",
       "  0.9999639987945557,\n",
       "  0.9999648332595825,\n",
       "  1.5864925444475375e-05,\n",
       "  9.675085311755538e-05,\n",
       "  5.486431109602563e-05,\n",
       "  9.130381658906117e-05,\n",
       "  0.0003830110945273191,\n",
       "  0.00365324504673481,\n",
       "  0.00027291098376736045,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.07312672585248947,\n",
       "  4.871400051342789e-06,\n",
       "  0.9681909680366516],\n",
       " '4': [],\n",
       " '5': [],\n",
       " '6': [],\n",
       " '7': [],\n",
       " '8': [],\n",
       " '9': [],\n",
       " '10': [],\n",
       " '11': []}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_dat['trial_T20190907_200104_945677_0']['p_state_change']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# old branch per-subgoal BASELINE\n",
    "\n",
    "{'epoch': 0,\n",
    " 'train_sanity': {'BLEU': 2.638813586708307e-232,\n",
    "                  'perplexity': 175.3822250366211,\n",
    "                  'total_loss': 7.454048156738281},\n",
    " 'valid_seen': {'BLEU': 2.7649164470978882e-232,\n",
    "                'perplexity': 180.12401580810547,\n",
    "                'total_loss': 7.491679668426514},\n",
    " 'valid_unseen': {'BLEU': 2.3879481169065848e-232,\n",
    "                  'perplexity': 160.17532348632812,\n",
    "                  'total_loss': 7.323445796966553}}\n",
    "epoch_time                    118.513                                 \n",
    "compute_metrics_validation_sets105.05                                  \n",
    "forward_batch_train_with_iterate12.287                                  \n",
    "forward_batch_train           11.946                                  \n",
    "iterate_featurize             0.326                                   \n",
    "torch_save_valid_seen         0.261                                   \n",
    "torch_save_last               0.252                                   \n",
    "torch_save_valid_unseen       0.247                                   \n",
    "torch_save_train_sanity       0.24                                    \n",
    "iterate_load_task_json        0.175                                   \n",
    "featurize_tensorization_and_padding0.158                                   \n",
    "featurize_input_resnet_features0.143                                   \n",
    "make_debug_valid_unseen       0.091                                   \n",
    "featurize_torch_load_time     0.09                                    \n",
    "make_debug_valid_seen         0.041                                   \n",
    "make_debug_train              0.041                                   \n",
    "setup_time                    0.001                                   \n",
    "featurize_input_action_low    0.0                                     \n",
    "compute_metrics_train         0.0                                     \n",
    "featurize_outputs             0.0 "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "{'epoch': 0,\n",
    " 'train_sanity': {'BLEU': 1.8747843191033304e-232,\n",
    "                  'perplexity': 176.1246566772461,\n",
    "                  'total_loss': 7.460198402404785},\n",
    " 'valid_seen': {'BLEU': 2.5034942568793152e-232,\n",
    "                'perplexity': 180.14256286621094,\n",
    "                'total_loss': 7.49180793762207},\n",
    " 'valid_unseen': {'BLEU': 2.1108175036585326e-232,\n",
    "                  'perplexity': 160.90531158447266,\n",
    "                  'total_loss': 7.330006122589111}}\n",
    "epoch_time                    229.403                                 \n",
    "compute_metrics_validation_sets193.46                                  \n",
    "forward_batch_train_with_iterate34.642                                  \n",
    "forward_batch_train           34.261                                  \n",
    "iterate_featurize             0.324                                   \n",
    "torch_save_valid_seen         0.274                                   \n",
    "torch_save_train_sanity       0.267                                   \n",
    "torch_save_last               0.263                                   \n",
    "torch_save_valid_unseen       0.262                                   \n",
    "iterate_load_task_json        0.216                                   \n",
    "featurize_input_resnet_features0.165                                   \n",
    "featurize_tensorization_and_padding0.158                                   \n",
    "make_debug_valid_seen         0.097                                   \n",
    "make_debug_train              0.092                                   \n",
    "featurize_torch_load_time     0.088                                   \n",
    "make_debug_valid_unseen       0.043                                   \n",
    "setup_time                    0.001                                   \n",
    "featurize_input_action_low    0.001                                   \n",
    "compute_metrics_train         0.0                                     \n",
    "featurize_outputs             0.0 "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# old branch BI-ATTN + AUX LOSS\n",
    "\n",
    "{'epoch': 0,\n",
    " 'train_sanity': {'BLEU': 5.272791609271694e-157,\n",
    "                  'perplexity': 133.40389251708984,\n",
    "                  'total_loss': 15.418501377105713},\n",
    " 'valid_seen': {'BLEU': 1.2697489715465426e-157,\n",
    "                'perplexity': 135.36600494384766,\n",
    "                'total_loss': 15.778061866760254},\n",
    " 'valid_unseen': {'BLEU': 1.3425960742964622e-157,\n",
    "                  'perplexity': 127.78440856933594,\n",
    "                  'total_loss': 15.614015579223633}}\n",
    "epoch_time                    237.858                                 \n",
    "compute_metrics_validation_sets204.668                                 \n",
    "forward_batch_train_with_iterate31.603                                  \n",
    "forward_batch_train           31.278                                  \n",
    "torch_save_train_sanity       0.344                                   \n",
    "iterate_featurize             0.34                                    \n",
    "torch_save_last               0.339                                   \n",
    "torch_save_valid_unseen       0.336                                   \n",
    "torch_save_valid_seen         0.327                                   \n",
    "featurize_tensorization_and_padding0.183                                   \n",
    "iterate_load_task_json        0.167                                   \n",
    "featurize_input_resnet_features0.134                                   \n",
    "make_debug_valid_unseen       0.101                                   \n",
    "make_debug_valid_seen         0.097                                   \n",
    "featurize_torch_load_time     0.076                                   \n",
    "make_debug_train              0.041                                   \n",
    "setup_time                    0.001                                   \n",
    "featurize_input_action_low    0.0                                     \n",
    "featurize_outputs             0.0                                     \n",
    "compute_metrics_train         0.0  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BI-ATTN + AUX LOSS\n",
    "\n",
    "{'epoch': 0,\n",
    " 'train_sanity': {'BLEU': 5.272791609271694e-157,\n",
    "                  'perplexity': 133.4038314819336,\n",
    "                  'total_loss': 15.418500900268555},\n",
    " 'valid_seen': {'BLEU': 1.2697489715465426e-157,\n",
    "                'perplexity': 135.36604690551758,\n",
    "                'total_loss': 15.778063297271729},\n",
    " 'valid_unseen': {'BLEU': 1.3425960742964622e-157,\n",
    "                  'perplexity': 127.78447341918945,\n",
    "                  'total_loss': 15.614017486572266}}\n",
    "epoch_time                    255.655                                 \n",
    "compute_metrics_validation_sets219.629                                 \n",
    "forward_batch_train_with_iterate34.462                                  \n",
    "forward_batch_train           34.142                                  \n",
    "torch_save_train_sanity       0.33                                    \n",
    "torch_save_valid_unseen       0.326                                   \n",
    "torch_save_last               0.326                                   \n",
    "torch_save_valid_seen         0.324                                   \n",
    "iterate_featurize             0.318                                   \n",
    "iterate_load_task_json        0.172                                   \n",
    "featurize_tensorization_and_padding0.162                                   \n",
    "featurize_input_resnet_features0.131                                   \n",
    "make_debug_valid_seen         0.105                                   \n",
    "make_debug_valid_unseen       0.093                                   \n",
    "featurize_torch_load_time     0.075                                   \n",
    "make_debug_train              0.053                                   \n",
    "setup_time                    0.001                                   \n",
    "compute_metrics_train         0.001                                   \n",
    "featurize_input_action_low    0.0                                     \n",
    "featurize_outputs             0.0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BI-ATTN + AUX LOSS\n",
    "# INSTANCE BASED\n",
    "\n",
    "{'epoch': 0,\n",
    " 'train_sanity': {'BLEU': 2.1643244568036305e-232,\n",
    "                  'perplexity': 256.3981170654297,\n",
    "                  'total_loss': 314.7671890258789},\n",
    " 'valid_seen': {'BLEU': 2.3009385374372878e-232,\n",
    "                'perplexity': 272.8842468261719,\n",
    "                'total_loss': 669.7962036132812},\n",
    " 'valid_unseen': {'BLEU': 2.33772413597026e-232,\n",
    "                  'perplexity': 273.24156188964844,\n",
    "                  'total_loss': 183.23194122314453}}\n",
    "epoch_time                    213.74                                  \n",
    "compute_metrics_validation_sets174.366                                 \n",
    "forward_batch_train_with_iterate37.815                                  \n",
    "forward_batch_train           37.342                                  \n",
    "iterate_featurize             0.563                                   \n",
    "featurize_tensorization_and_padding0.371                                   \n",
    "torch_save_train_sanity       0.357                                   \n",
    "torch_save_valid_unseen       0.343                                   \n",
    "torch_save_valid_seen         0.337                                   \n",
    "torch_save_last               0.336                                   \n",
    "iterate_load_task_json        0.19                                    \n",
    "featurize_input_resnet_features0.129                                   \n",
    "make_debug_valid_unseen       0.099                                   \n",
    "featurize_torch_load_time     0.074                                   \n",
    "make_debug_valid_seen         0.042                                   \n",
    "make_debug_train              0.042                                   \n",
    "setup_time                    0.001                                   \n",
    "featurize_input_action_low    0.0                                     \n",
    "compute_metrics_train         0.0                                     \n",
    "featurize_outputs             0.0 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training cycle debugging\n",
    "\n",
    "Basically run code copied from train_seq2seq.py in this notebook to catch bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['ALFRED_ROOT'] = '/root/data/home/hoyeung/alfred/'\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.environ['ALFRED_ROOT']))\n",
    "sys.path.append(os.path.join(os.environ['ALFRED_ROOT'], 'models'))\n",
    "\n",
    "# from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser\n",
    "import torch\n",
    "import pprint\n",
    "import json\n",
    "from data.preprocess import Dataset\n",
    "from importlib import import_module, reload\n",
    "from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser\n",
    "from models.utils.helper_utils import optimizer_to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the default flags present in train_seq2seq.py\n",
    "\n",
    "parser = ArgumentParser(formatter_class=ArgumentDefaultsHelpFormatter)\n",
    "args = parser.parse_args('')\n",
    "\n",
    "# settings\n",
    "args.seed = 123\n",
    "args.data = '/root/data_alfred/json_feat_2.1.0'\n",
    "args.splits = '/root/data_alfred/splits/may17.json'\n",
    "args.object_vocab = 'objects_20200522'\n",
    "args.preprocess = False #!\n",
    "args.pp_folder = 'pp'\n",
    "args.monitor_train_every = 10\n",
    "args.save_every_epoch = False #!\n",
    "args.model = 'seq2seq_per_subgoal'\n",
    "args.gpu = True\n",
    "args.dout = 'exp/model:seq2seq_per_subgoal'\n",
    "args.resume = False #!\n",
    "\n",
    "# hyper parameters\n",
    "args.batch = 8\n",
    "args.epoch = 20\n",
    "args.lr = 1e-4\n",
    "args.decay_epoch = 10\n",
    "args.dhid = 512\n",
    "args.dframe = 2500\n",
    "args.demb = 100\n",
    "args.pframe = 300\n",
    "args.mask_loss_wt = 1.\n",
    "args.action_loss_wt = 1.\n",
    "args.subgoal_aux_loss_wt = 0.\n",
    "args.pm_aux_loss_wt = 0.\n",
    "\n",
    "# architecture ablations\n",
    "# args.maxpool_over_object_states = False\n",
    "# args.aux_loss_over_object_states = False\n",
    "args.encoder_addons = 'none'\n",
    "args.decoder_addons = 'none'\n",
    "\n",
    "# dropouts\n",
    "args.zero_goal = False #!\n",
    "args.zero_instr = False #!\n",
    "args.act_dropout = 0.\n",
    "args.lang_dropout = 0.\n",
    "args.input_dropout = 0.\n",
    "args.vis_dropout = 0.3\n",
    "args.hstate_dropout = 0.3\n",
    "args.attn_dropout = 0.\n",
    "args.actor_dropout = 0.\n",
    "args.word_dropout = 0.\n",
    "\n",
    "# other settings\n",
    "args.train_teacher_forcing = False #!\n",
    "args.train_student_forcing_prob = 0.1\n",
    "args.temp_no_history = False #!\n",
    "\n",
    "# debugging\n",
    "args.fast_epoch = False #!\n",
    "args.dataset_fraction = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite the default flags\n",
    "\n",
    "args.preprocess = False # Turn this to True if running for the first time\n",
    "\n",
    "args.model = 'seq2seq_per_subgoal'  # found under models/model/ directory\n",
    "args.dout = '/root/data_alfred/exp/model:seq2seq_per_subgoal_biattn_fast_epoch'\n",
    "\n",
    "args.train_teacher_forcing = True\n",
    "args.gpu = False\n",
    "\n",
    "# light setup for debugging\n",
    "args.fast_epoch = True # Turn this to False if running for the first time to preprocess data properly\n",
    "args.epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.maxpool_over_object_states = True\n",
    "# args.aux_loss_over_object_states = True\n",
    "\n",
    "# args.encoder_addons = 'biattn_obj'\n",
    "# args.decoder_addons = 'aux_loss'\n",
    "args.encoder_addons = 'biattn_obj'\n",
    "args.decoder_addons = 'aux_loss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f0cd412f830>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and load data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.out  /root/data_alfred/exp/model:seq2seq_per_subgoal_biattn_fast_epoch\n"
     ]
    }
   ],
   "source": [
    "# make output dir\n",
    "if not os.path.isdir(args.dout):\n",
    "    os.makedirs(args.dout)\n",
    "\n",
    "print('args.out ', args.dout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tests_seen': 1533,\n",
      " 'tests_unseen': 1529,\n",
      " 'train': 20806,\n",
      " 'train_sanity': 246,\n",
      " 'train_sanity_v1': 246,\n",
      " 'valid_seen': 814,\n",
      " 'valid_seen_v1': 249,\n",
      " 'valid_unseen': 818,\n",
      " 'valid_unseen_v1': 254}\n"
     ]
    }
   ],
   "source": [
    "# load train/valid/tests splits\n",
    "with open(args.splits) as f:\n",
    "    splits = json.load(f)\n",
    "    pprint.pprint({k: len(v) for k, v in splits.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action_high': Vocab(93), 'word': Vocab(2360), 'action_low': Vocab(15)}\n"
     ]
    }
   ],
   "source": [
    "# preprocess and save -- only need to preprocess once\n",
    "if args.preprocess:\n",
    "    print(\"\\nPreprocessing dataset and saving to %s folders ... This will take a while. Do this once as required.\" % args.pp_folder)\n",
    "    dataset = Dataset(args, None)\n",
    "    dataset.preprocess_splits(splits)\n",
    "    vocab = torch.load(os.path.join(args.dout, \"%s.vocab\" % args.pp_folder))\n",
    "else:\n",
    "    vocab = torch.load(os.path.join(args.data, \"%s.vocab\" % args.pp_folder))\n",
    "    \n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_vocab = torch.load(os.path.join(args.data, '%s.vocab' % args.object_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model architecture\n",
    "args.gpu = False\n",
    "args.resume = None # os.path.join(args.dout, 'best_seen.pth')\n",
    "\n",
    "M = import_module('model.{}'.format(args.model))\n",
    "if args.resume:\n",
    "    print(\"Loading: \" + args.resume)\n",
    "    model, optimizer, start_epoch = M.Module.load(args.resume)\n",
    "    print(\"Restarting at epoch {}/{}\".format(start_epoch, args.epoch-1))\n",
    "    if start_epoch >= args.epoch:\n",
    "        print('Checkpoint already finished {}/{} epochs.'.format(start_epoch, args.epoch))\n",
    "        sys.exit(0)\n",
    "else:\n",
    "    model = M.Module(args, vocab, object_vocab)\n",
    "    optimizer = None\n",
    "    start_epoch = 0\n",
    "\n",
    "if args.gpu:\n",
    "    model = model.to(torch.device('cuda'))\n",
    "    if not optimizer is None:\n",
    "        optimizer_to(optimizer, torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Module(\n",
       "  (emb_word): Embedding(2360, 100)\n",
       "  (emb_action_low): Embedding(15, 100)\n",
       "  (emb_object): Embedding(111, 512, padding_idx=0)\n",
       "  (enc): ActionFrameAttnEncoderPerSubgoalObjAttn(\n",
       "    (emb): Embedding(15, 100)\n",
       "    (vis_dropout): Dropout(p=0.3, inplace=False)\n",
       "    (act_dropout): Dropout(p=0.0, inplace=True)\n",
       "    (vis_encoder): ResnetVisualEncoder(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (fc): Linear(in_features=3136, out_features=2500, bias=True)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (enc_att): SelfAttn(\n",
       "      (scorer): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    )\n",
       "    (encoder): LSTM(2600, 512, batch_first=True, bidirectional=True)\n",
       "    (input_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (hstate_dropout): Dropout(p=0.3, inplace=False)\n",
       "    (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (obj_emb): Embedding(111, 512, padding_idx=0)\n",
       "    (obj_attn): DotAttn()\n",
       "    (h_tm1_fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (forward_cell): LSTMCell(3624, 512)\n",
       "    (backward_cell): LSTMCell(3624, 512)\n",
       "  )\n",
       "  (dec): LanguageDecoder(\n",
       "    (emb): Embedding(2360, 100)\n",
       "    (obj_emb): Embedding(111, 512, padding_idx=0)\n",
       "    (cell): LSTMCell(1124, 1024)\n",
       "    (attn): DotAttn()\n",
       "    (input_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (hstate_dropout): Dropout(p=0.3, inplace=False)\n",
       "    (word_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (word): Linear(in_features=2148, out_features=100, bias=True)\n",
       "    (h_tm1_fc): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (h_enc_fc): Linear(in_features=1, out_features=2, bias=True)\n",
       "  )\n",
       "  (vis_dropout): Dropout(p=0.3, inplace=False)\n",
       "  (act_dropout): Dropout(p=0.0, inplace=True)\n",
       "  (aux_criterion): BCEWithLogitsLoss()\n",
       "  (language_crtierion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine model layers\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to: /root/data_alfred/exp/model:seq2seq_per_subgoal_biattn_fast_epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/data/home/hoyeung/alfred/models/model/seq2seq_per_subgoal.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  empty_tensor = torch.ones(torch.tensor(v[0][0][0]).unsqueeze(0).shape, device=device, dtype=torch.float if ('frames' in k) else torch.long) * self.pad\n",
      "/root/data/home/hoyeung/alfred/models/model/seq2seq_per_subgoal.py:278: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  seqs.append(torch.tensor(v[subgoal_i][batch_i], device=device, dtype=torch.float if ('frames' in k) else torch.long))\n",
      "/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/functional.py:1350: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "\n",
      "batch:  50%|█████     | 1/2 [00:15<00:15, 15.31s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:31<00:00, 15.80s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:03<00:03,  3.84s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:06<00:00,  3.33s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:06<00:06,  6.06s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:12<00:00,  6.07s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:04<00:04,  4.03s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:08<00:00,  4.25s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:29<00:29, 29.20s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:43<00:00, 21.67s/it]\u001b[A\n",
      "/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:33<00:33, 33.31s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [01:05<00:00, 32.98s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:32<00:32, 32.59s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [01:06<00:00, 33.47s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found new best valid_seen!! Saving...\n",
      "Found new best valid_unseen!! Saving...\n",
      "Found new best train_sanity!! Saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  20%|██        | 1/5 [03:57<15:51, 237.86s/it]\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0,\n",
      " 'train_sanity': {'BLEU': 5.272791609271694e-157,\n",
      "                  'perplexity': 133.40389251708984,\n",
      "                  'total_loss': 15.418501377105713},\n",
      " 'valid_seen': {'BLEU': 1.2697489715465426e-157,\n",
      "                'perplexity': 135.36600494384766,\n",
      "                'total_loss': 15.778061866760254},\n",
      " 'valid_unseen': {'BLEU': 1.3425960742964622e-157,\n",
      "                  'perplexity': 127.78440856933594,\n",
      "                  'total_loss': 15.614015579223633}}\n",
      "epoch_time                    237.858                                 \n",
      "compute_metrics_validation_sets204.668                                 \n",
      "forward_batch_train_with_iterate31.603                                  \n",
      "forward_batch_train           31.278                                  \n",
      "torch_save_train_sanity       0.344                                   \n",
      "iterate_featurize             0.34                                    \n",
      "torch_save_last               0.339                                   \n",
      "torch_save_valid_unseen       0.336                                   \n",
      "torch_save_valid_seen         0.327                                   \n",
      "featurize_tensorization_and_padding0.183                                   \n",
      "iterate_load_task_json        0.167                                   \n",
      "featurize_input_resnet_features0.134                                   \n",
      "make_debug_valid_unseen       0.101                                   \n",
      "make_debug_valid_seen         0.097                                   \n",
      "featurize_torch_load_time     0.076                                   \n",
      "make_debug_train              0.041                                   \n",
      "setup_time                    0.001                                   \n",
      "featurize_input_action_low    0.0                                     \n",
      "featurize_outputs             0.0                                     \n",
      "compute_metrics_train         0.0                                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "batch:  50%|█████     | 1/2 [00:14<00:14, 14.89s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:28<00:00, 14.10s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:03<00:03,  3.36s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:05<00:00,  2.72s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "batch:  50%|█████     | 1/2 [00:05<00:05,  5.55s/it]\u001b[A\n",
      "batch: 100%|██████████| 2/2 [00:10<00:00,  5.41s/it]\u001b[A\n",
      "\n",
      "batch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "epoch:  20%|██        | 1/5 [04:43<18:52, 283.08s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2a79b170a1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# main training loop -- debug here if breakpoints were inserted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/data/home/hoyeung/alfred/models/model/seq2seq.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(self, splits, args, optimizer, start_epoch)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;31m# compute metrics for valid_unseen, teacher forcing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_valid_unseen_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_valid_unseen_teacher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_unseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid_unseen'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_unseen_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_teacher_forcing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m             \u001b[0mm_valid_unseen_teacher\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_valid_unseen_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'valid_unseen/epoch_perplexity_teacher_forcing'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_valid_unseen_teacher\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'perplexity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_no_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/home/hoyeung/alfred/models/model/seq2seq.py\u001b[0m in \u001b[0;36mrun_pred\u001b[0;34m(self, dev, args, name, iter, validate_teacher_forcing, validate_sample_output)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mdev_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterate_time_report\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_teacher_forcing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_teacher_forcing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_sample_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_sample_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mp_dev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/home/hoyeung/alfred/models/model/seq2seq_per_subgoal.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, feat, max_decode, validate_teacher_forcing, validate_sample_output)\u001b[0m\n\u001b[1;32m    376\u001b[0m                 \u001b[0mmax_decode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_decode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m                 \u001b[0mvalidate_teacher_forcing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_teacher_forcing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m                 validate_sample_output=validate_sample_output)\n\u001b[0m\u001b[1;32m    379\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres_subgoal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0mfeat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubgoal_i\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres_subgoal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/home/hoyeung/alfred/models/model/seq2seq_per_subgoal.py\u001b[0m in \u001b[0;36mforward_one_subgoal\u001b[0;34m(self, feat_subgoal, max_decode, validate_teacher_forcing, validate_sample_output)\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0mvalid_object_indices\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mfeat_subgoal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'object_token_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maux_loss_over_object_states\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mvalidate_teacher_forcing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_teacher_forcing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m             \u001b[0mvalidate_sample_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_sample_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m             )\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/home/hoyeung/alfred/models/nn/vnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, enc, gold, max_decode, state_0, valid_object_indices, validate_teacher_forcing, validate_sample_output)\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m             \u001b[0mword_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_score_t\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m             \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m             \u001b[0mattn_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_score_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/home/hoyeung/alfred/models/nn/vnn.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, enc, e_t, state_tm1)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0mcont_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_t\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m         \u001b[0;31m# (B, demb)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m         \u001b[0mword_emb_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcont_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m         \u001b[0;31m# (B, demb).mm(demb, vocab size) = (B, vocab size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0mword_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_emb_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# main training loop -- debug here if breakpoints were inserted\n",
    "model.run_train(splits, optimizer=optimizer, start_epoch=start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASELINE PER SUBGOAL\n",
    "\n",
    "{'epoch': 0,\n",
    " 'train_sanity': {'BLEU': 2.638813586708307e-232,\n",
    "                  'perplexity': 175.3822250366211,\n",
    "                  'total_loss': 7.454048156738281},\n",
    " 'valid_seen': {'BLEU': 2.7649164470978882e-232,\n",
    "                'perplexity': 180.12401580810547,\n",
    "                'total_loss': 7.491679668426514},\n",
    " 'valid_unseen': {'BLEU': 2.3879481169065848e-232,\n",
    "                  'perplexity': 160.17532348632812,\n",
    "                  'total_loss': 7.323445796966553}}\n",
    "epoch_time                    118.513                                 \n",
    "compute_metrics_validation_sets105.05                                  \n",
    "forward_batch_train_with_iterate12.287                                  \n",
    "forward_batch_train           11.946                                  \n",
    "iterate_featurize             0.326                                   \n",
    "torch_save_valid_seen         0.261                                   \n",
    "torch_save_last               0.252                                   \n",
    "torch_save_valid_unseen       0.247                                   \n",
    "torch_save_train_sanity       0.24                                    \n",
    "iterate_load_task_json        0.175                                   \n",
    "featurize_tensorization_and_padding0.158                                   \n",
    "featurize_input_resnet_features0.143                                   \n",
    "make_debug_valid_unseen       0.091                                   \n",
    "featurize_torch_load_time     0.09                                    \n",
    "make_debug_valid_seen         0.041                                   \n",
    "make_debug_train              0.041                                   \n",
    "setup_time                    0.001                                   \n",
    "featurize_input_action_low    0.0                                     \n",
    "compute_metrics_train         0.0                                     \n",
    "featurize_outputs             0.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BI-ATTN + AUX LOSS\n",
    "\n",
    "{'epoch': 0,\n",
    " 'train_sanity': {'BLEU': 5.272791609271694e-157,\n",
    "                  'perplexity': 133.40389251708984,\n",
    "                  'total_loss': 15.418501377105713},\n",
    " 'valid_seen': {'BLEU': 1.2697489715465426e-157,\n",
    "                'perplexity': 135.36600494384766,\n",
    "                'total_loss': 15.778061866760254},\n",
    " 'valid_unseen': {'BLEU': 1.3425960742964622e-157,\n",
    "                  'perplexity': 127.78440856933594,\n",
    "                  'total_loss': 15.614015579223633}}\n",
    "epoch_time                    237.858                                 \n",
    "compute_metrics_validation_sets204.668                                 \n",
    "forward_batch_train_with_iterate31.603                                  \n",
    "forward_batch_train           31.278                                  \n",
    "torch_save_train_sanity       0.344                                   \n",
    "iterate_featurize             0.34                                    \n",
    "torch_save_last               0.339                                   \n",
    "torch_save_valid_unseen       0.336                                   \n",
    "torch_save_valid_seen         0.327                                   \n",
    "featurize_tensorization_and_padding0.183                                   \n",
    "iterate_load_task_json        0.167                                   \n",
    "featurize_input_resnet_features0.134                                   \n",
    "make_debug_valid_unseen       0.101                                   \n",
    "make_debug_valid_seen         0.097                                   \n",
    "featurize_torch_load_time     0.076                                   \n",
    "make_debug_train              0.041                                   \n",
    "setup_time                    0.001                                   \n",
    "featurize_input_action_low    0.0                                     \n",
    "featurize_outputs             0.0                                     \n",
    "compute_metrics_train         0.0  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
